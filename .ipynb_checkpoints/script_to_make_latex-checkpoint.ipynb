{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-hebrew-numbers in c:\\users\\nkasimer\\anaconda3\\lib\\site-packages (0.2.3)\n",
      "Requirement already satisfied: PyYaml in c:\\users\\nkasimer\\anaconda3\\lib\\site-packages (from python-hebrew-numbers) (5.1.2)\n",
      "Requirement already satisfied: pdfrw in c:\\users\\nkasimer\\anaconda3\\lib\\site-packages (0.4)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install python-hebrew-numbers\n",
    "!{sys.executable} -m pip install pdfrw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports various packages\n",
    "import json, urllib.request\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "import os, platform, subprocess, csv\n",
    "import math\n",
    "from hebrew_numbers import int_to_gematria\n",
    "import pdfrw\n",
    "from pdfrw import PdfReader, PdfWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function pulls a text from Sefaria's github repo, given a string with the name of the text in the repo's format\n",
    "#this will presumably be replaced with pulling a text from a downloaded copy of the sefaria repo\n",
    "def pull_text(string_for_link):\n",
    "    link = \"https://raw.githubusercontent.com/Sefaria/Sefaria-Export/master/json/\"+string_for_link.replace(\" \",\"%20\")+\".json\"\n",
    "    print(link)\n",
    "    with urllib.request.urlopen(link) as url:\n",
    "        text_json = json.loads(url.read().decode())\n",
    "    return text_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this generates a list of links between texts in sefaria\n",
    "#this is used to link comments in the gemara to gemara they're on\n",
    "def pull_links():\n",
    "    link_list = []#blank list to be filled in\n",
    "    for i in range(9):#this increments through all the github files that contain links\n",
    "        location = os.path.join(os.getcwd(),\"links\",\"links\"+str(i)+\".csv\")\n",
    "        with open(location, encoding=\"utf-8\") as csv_file:\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            next(csv_reader)#skips first row\n",
    "            for row in csv_reader:\n",
    "                if row[2] == \"commentary\":#only interested in commentaries\n",
    "                    link = []\n",
    "                    link.append(row[0])\n",
    "                    link.append(row[1])\n",
    "                    link_list.append(link)\n",
    "    return link_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_list = pull_links()#generates the list of comment links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_comment(comment_str, links):#matches a comment with the gemara it's on\n",
    "    for link in links:#for every link in the list\n",
    "        #if the text is in the list, return the text it's linked to\n",
    "        if comment_str in link[0]:\n",
    "            return link[1]\n",
    "        elif comment_str in link[1]:\n",
    "            return link[0]\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_json(masekhet):\n",
    "    #this gets the index json for a particular masekhet, which includes info about perakim.\n",
    "    masekhet = masekhet.replace(\" \",\"_\")\n",
    "    link = \"https://raw.githubusercontent.com/Sefaria/Sefaria-Export/master/schemas/\"+masekhet+\".json\"\n",
    "    with urllib.request.urlopen(link) as url:\n",
    "        index_json = json.loads(url.read().decode())\n",
    "    chaps = index_json[\"alts\"][\"Chapters\"][\"nodes\"]\n",
    "    return chaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_perek(name):\n",
    "    if \" on \" in name:\n",
    "        masekhet_start = name.find(\" on \")+len(\" on \")\n",
    "        name = name[masekhet_start:]\n",
    "    name = name.split(' ')\n",
    "    if len(name)==2:\n",
    "        masekhet = name[0]\n",
    "    else:\n",
    "        masekhet = name[0]+\" \"+name[1]\n",
    "    daf,line = name[-1].split(\":\")\n",
    "    chapters = get_index_json(masekhet)\n",
    "    ref = masekhet+\" \"+daf\n",
    "    for chapter in chapters:\n",
    "        for page in chapter[\"refs\"]:\n",
    "            if \":\" not in page and page==ref:\n",
    "                return chapter[\"title\"],chapter['heTitle']\n",
    "            elif \":\" in page and ref in page:\n",
    "                sections = page.split(\":\")[1]\n",
    "                sections = sections.split(\"-\")\n",
    "                if len(sections)>1:\n",
    "                    if int(sections[0])<=int(line)<=int(sections[1]):\n",
    "                        return chapter[\"title\"],chapter['heTitle']\n",
    "                elif len(sections) == 1:\n",
    "                    if int(sections[0])==int(line):\n",
    "                        return chapter[\"title\"],chapter['heTitle']\n",
    "    return ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_chapters(text_json, links):\n",
    "    #adds perek breaks to text json\n",
    "    refs = []\n",
    "    text_json[\"text_perakim\"] = []#original text, but with perakim breaks noted\n",
    "    text_json[\"chap_list\"] = []#list of chapter titles\n",
    "    daf_i = 1#initializing counters.\n",
    "    #Sefaria puts a blank spot for daf 1, so it starts with 1 not 2.\n",
    "    title = text_json[\"title\"]\n",
    "    current_perek = \"\"\n",
    "    j=0\n",
    "    for daf in text_json[\"text\"]:\n",
    "        if daf != []:#if daf isn't empty\n",
    "            comment_i = 1#comment counter\n",
    "            for comment in daf:\n",
    "                daf_num = math.floor(daf_i)#rounds daf down from 0.5 to get real number\n",
    "                if daf_num == daf_i:\n",
    "                    amud = \"a\"\n",
    "                else:\n",
    "                    amud = \"b\"#for daf with 0.5, it's daf X amud b\n",
    "                daf_ref = str(daf_num)+amud #makes davening number, like 4b\n",
    "                new_ref = title +\" \"+ daf_ref + \":\"+str(comment_i)\n",
    "                #adds masekhet name to daf reference\n",
    "                if \"commentary\" in text_json[\"categories\"]:\n",
    "                    gemara_ref = \"\"\n",
    "                    for link in links:#for every link in link list\n",
    "                        if link[0] == new_ref:#if the link is do the relevant daf\n",
    "                            gemara_ref = link[1]\n",
    "                            break\n",
    "                    if \"-\" in gemara_ref:#if a reference spans a daf\n",
    "                        gemara_ref = gemara_ref.split(\"-\")[0]#returns the first part\n",
    "                    if gemara_ref != \"\":\n",
    "                        ref_perek = find_perek(gemara_ref)#looks up the perek of the daf of gemara\n",
    "                        if ref_perek != current_perek:#if the reference is a new perek\n",
    "                            current_perek = ref_perek#set current perek\n",
    "                            perek_info = {\"name_en\":ref_perek[0],\"name_he\":ref_perek[1]}\n",
    "                            text_json[\"text\"][j].insert(comment_i-1,perek_info)\n",
    "                            #the above adds a dict with info on the perek into the text json\n",
    "                else:\n",
    "                    ref_perek = find_perek(new_ref)\n",
    "                    if ref_perek != current_perek:#if the reference is a new perek\n",
    "                        current_perek = ref_perek#set current perek\n",
    "                        perek_info = {\"name_en\":ref_perek[0],\"name_he\":ref_perek[1]}\n",
    "                        if perek_info not in text_json[\"text\"] and perek_info != {'name_en': 'N', 'name_he': 'i'}:\n",
    "                            text_json[\"text\"][j].insert(comment_i-1,perek_info)\n",
    "                        #the above adds a dict with info on the perek into the text json\n",
    "                comment_i += 1\n",
    "        daf_i += 0.5\n",
    "        j += 1\n",
    "    return text_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_body_json(hebrew_text, english_text, settings, commentaries):\n",
    "    output = []\n",
    "    parbreak = \"\\n\\n\"\n",
    "    title = hebrew_text[\"heTitle\"]\n",
    "    title_command = r\"\\newcommand{\\texttitle}{\"+title+\"}\"#sets title\n",
    "    chap_num = 0\n",
    "    structure = hebrew_text[\"schema\"][\"nodes\"]\n",
    "    for chapter in hebrew_text[\"text\"].items():\n",
    "        chap_title_eng = chapter[0]\n",
    "        chap_content = chapter[1]\n",
    "        chap_title_he = \"\"\n",
    "        for chap_name in structure:\n",
    "            if chap_title_eng == chap_name[\"enTitle\"]:\n",
    "                chap_title_he = chap_name[\"heTitle\"]\n",
    "                break\n",
    "        if settings[\"newpage\"] == 1:\n",
    "            output.append(r\"\\clearpage\")\n",
    "        new_chap_text = r\"\\newchap{\"+chap_title_he+\"}\"\n",
    "        output.append(new_chap_text)\n",
    "        if type(chap_content) == list:# if the chapter has text, rather than subsections:\n",
    "            i=0\n",
    "            for par in chap_content:\n",
    "                #prints next block of text\n",
    "                textblock = \"\"\n",
    "                comments = []\n",
    "                if type(par)==list:\n",
    "                    j=0\n",
    "                    for chunk in par:\n",
    "                        if english_text != None and english_text[\"text\"][chap_title_eng] != []:\n",
    "                            new_text = make_section_json(chunk,english_text[\"text\"][chap_title_eng][i][j], settings, commentaries,chap_title_eng,i,j)\n",
    "                        else:\n",
    "                            new_text = make_section_json(chunk,None, settings, commentaries,chap_title_eng,i,j)\n",
    "                        if new_text != \"\":\n",
    "                            output.append(new_text)\n",
    "                        j+=1\n",
    "                elif type(par)==str:\n",
    "                    if english_text != None and english_text[\"text\"][chap_title_eng] != []:\n",
    "                        new_text = make_section_json(par,english_text[\"text\"][chap_title_eng][i], settings, commentaries,chap_title_eng,i,None)\n",
    "                    else:\n",
    "                        new_text = make_section_json(par,None, settings, commentaries,chap_title_eng,i,None)\n",
    "                    if new_text != \"\":\n",
    "                        output.append(new_text)\n",
    "                i += 1\n",
    "        elif type(chap_content)==dict:#if chapter contains sections\n",
    "            chap_structure = structure[chap_num][\"nodes\"]\n",
    "            sect_num = 0\n",
    "            for section in chap_content.items():\n",
    "                sect_title_eng = section[0]\n",
    "                sect_content = section[1]\n",
    "                sect_title_he = \"\"\n",
    "                for sect_name in chap_structure:#[chap_title_eng]:\n",
    "                    if sect_title_eng == sect_name[\"enTitle\"]:\n",
    "                        sect_title_he = sect_name[\"heTitle\"]\n",
    "                        break\n",
    "                new_section_text = r\"\\newsection{\"+sect_title_he+\"}\"\n",
    "                output.append(new_section_text)\n",
    "                if type(section[1]) == list:\n",
    "                    j = 0\n",
    "                    for par in section[1]:\n",
    "                        #prints next block of text\n",
    "                        textblock = \"\"\n",
    "                        comments = []\n",
    "                        while type(par)==list:\n",
    "                            new_par = \"\"\n",
    "                            for item in par:\n",
    "                                new_par += item\n",
    "                            par = new_par\n",
    "                        if type(par) != dict:\n",
    "                            textblock += par\n",
    "                        if english_text != None and english_text[\"text\"][chap_title_eng][sect_title_eng] != []:\n",
    "                            textblock_eng = \"\"\n",
    "                            if type(english_text[\"text\"][chap_title_eng][sect_title_eng])==list and len(english_text[\"text\"][chap_title_eng][sect_title_eng]) == 1:\n",
    "                                par_eng = english_text[\"text\"][chap_title_eng][sect_title_eng][0]\n",
    "                            else:\n",
    "                                par_eng = english_text[\"text\"][chap_title_eng][sect_title_eng][j]\n",
    "                           # except:\n",
    "                            #    print(j,english_text[\"text\"][chap_title_eng][sect_title_eng])\n",
    "                            while type(par_eng) == list:\n",
    "                                new_par_eng = \"\"\n",
    "                                for item in par_eng:\n",
    "                                    new_par_eng += item\n",
    "                                par_eng = new_par_eng\n",
    "                            if type(par_eng) != dict:\n",
    "                                textblock_eng += par_eng\n",
    "                            new_text = make_section_json(textblock,textblock_eng, settings, commentaries,chap_title_eng,sect_title_eng,j)\n",
    "                        else:\n",
    "                            new_text = make_section_json(textblock,None, settings, commentaries,chap_title_eng,sect_title_eng,j)\n",
    "                        if new_text != \"\":\n",
    "                            output.append(new_text)\n",
    "                        j += 1\n",
    "                elif type(section[1]) == dict:#if section contains subsections\n",
    "                    sect_structure = chap_structure[sect_num][\"nodes\"]\n",
    "                    for subsection in section[1].items():\n",
    "                        subsect_title_eng = subsection[0]\n",
    "                        subsect_content = subsection[1]\n",
    "                        subsect_title_he = \"\"\n",
    "                        for subsect_name in sect_structure:\n",
    "                            if subsect_title_eng == subsect_name[\"enTitle\"]:\n",
    "                                subsect_title_he = subsect_name[\"heTitle\"]\n",
    "                                break\n",
    "                        new_subsection_text = r\"\\newsubsection{\"+subsect_title_he+\"}\"\n",
    "                        output.append(new_subsection_text)\n",
    "                        subsect_i = 0\n",
    "                        for par in subsection[1]:\n",
    "                            #prints next block of text\n",
    "                            textblock = \"\"\n",
    "                            comments = []\n",
    "                            while type(par)==list:\n",
    "                                new_par = \"\"\n",
    "                                for item in par:\n",
    "                                    new_par += item\n",
    "                                par = new_par\n",
    "                            if type(par) != dict:\n",
    "                                textblock += par\n",
    "                            if english_text != None and english_text[\"text\"][chap_title_eng][sect_title_eng] != []:#[subsect_i]\n",
    "                                #try:\n",
    "                                eng_subsect = english_text[\"text\"][chap_title_eng][sect_title_eng]\n",
    "                                textblock_eng = \"\"\n",
    "                                while type(eng_subsect) == list:\n",
    "                                    new_par_eng = \"\"\n",
    "                                    for item in eng_subsect:\n",
    "                                        new_par_eng + item\n",
    "                                    eng_subsect = new_par_eng\n",
    "                                if type(eng_subsect) != dict:\n",
    "                                    textblock_eng += eng_subsect\n",
    "                                    #new_par_eng = english_text[\"text\"][chap_title_eng][sect_title_eng][subsect_i]\n",
    "                             #   except:\n",
    "                              #      print(english_text[\"text\"][chap_title_eng][sect_title_eng])\n",
    "#                                 for item in english_text[\"text\"][chap_title_eng][sect_title_eng]:\n",
    "#                                     new_par_eng += item + parbreak\n",
    "                                new_text = make_section_json(textblock,textblock_eng, settings, commentaries,chap_title_eng,sect_title_eng,subsect_title_eng)\n",
    "                            else:\n",
    "                                new_text = make_section_json(textblock,None, settings, commentaries,chap_title_eng,sect_title_eng,subsect_title_eng)\n",
    "                            if new_text != \"\":\n",
    "                                output.append(new_text)\n",
    "                            subsect_i += 1\n",
    "\n",
    "                sect_num += 1\n",
    "        chap_num += 1\n",
    "    if settings[\"layout\"] == \"twocol\" and english_text == None:\n",
    "        line_i = 0\n",
    "        newsection_bool = True\n",
    "        in_cols = False\n",
    "        lastline = \"\"\n",
    "        for line in output:\n",
    "            if \"newsection\" in line or \"newchap\" in line or \"newsubsection\" in line:\n",
    "                newsection_bool = True\n",
    "                if in_cols == True:\n",
    "                    #print(\"END TWOCOLS\")\n",
    "                    if settings[\"newpage\"] < 2:\n",
    "                        end_multicols = \"\\n\"+r\"\\end{multicols}\\newpage\"+\"\\n\"\n",
    "                    else:\n",
    "                        end_multicols = \"\\n\"+r\"\\end{multicols}\"+\"\\n\"\n",
    "                    output[line_i-1] = output[line_i-1]+end_multicols\n",
    "                    in_cols = False\n",
    "            elif \"newsection\" not in line and \"newchap\" not in line and \"renewcommand\" not in line and \"fancy\" not in line:\n",
    "                if newsection_bool == True:\n",
    "                    newsection_bool = False\n",
    "                    #output[line_i] = r\"\\twocol{\"+line\n",
    "                    output[line_i] = r\"\\begin{multicols}{2}\"+\"\\n\"+line\n",
    "                    in_cols = True\n",
    "                    #print(\"BEGIN TWOCOLS\")\n",
    "\n",
    "            lastline = line\n",
    "            line_i += 1\n",
    "        #output.append(r\"}\")\n",
    "        output.append(r\"\\end{multicols}\")\n",
    "        output.append(r\"\\newpage\")\n",
    "        \n",
    "    return title_command, output, title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_section_json(hebrew_text,english,settings,commentaries,chap,sect,subsect):\n",
    "#def make_section(hebrew_text, english, settings, chap_num, mishna_num, commentaries):\n",
    "    hebrew_text = footnoteremove(hebrew_text)\n",
    "    english = footnoteremove(english)\n",
    "    with open('resources/text_replacements.csv',encoding='utf-8') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            if row[0] in hebrew_text:\n",
    "                hebrew_text = hebrew_text.replace(row[0],row[1])\n",
    "    if english != None and english != \"\":\n",
    "        with open('resources/english_replacements.csv',encoding='utf-8') as csv_file:\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            next(csv_reader)\n",
    "            for row in csv_reader:\n",
    "                if row[0] in english:\n",
    "                    english = english.replace(row[0],row[1])\n",
    "    #turns a block of text into a latex section using the \\textblock or \\twocol command\n",
    "    if english != None:\n",
    "        english = english.replace(\"[\",\"{[\")\n",
    "        english = english.replace(\"]\",\"]}\")\n",
    "        output = r\"\\hebeng{\"+hebrew_text+\"}{\"+english+\"}\"\n",
    "        if settings[\"newpage\"] == 1:\n",
    "            output += r\"\\newpage\"\n",
    "    elif settings[\"layout\"] == \"twocol\":\n",
    "        #output= r\"\\twocol{\"+hebrew_text+\"}\"\n",
    "        output = hebrew_text\n",
    "    elif hebrew_text==\"\":\n",
    "        output = \"\"\n",
    "    else:\n",
    "        output= r\"\\textblock{\"+hebrew_text+\"}\"\n",
    "    commentary_i = 1\n",
    "    for commentary in commentaries:\n",
    "        #output+=\"\\n\"\n",
    "        output+=get_comments_json(commentary,chap,sect,subsect,commentary_i)\n",
    "        commentary_i += 1\n",
    "    output = removeformatting(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments_json(commentary,chap,sect,subsect,comment_i):\n",
    "    if subsect != None:\n",
    "        try:\n",
    "            comments = commentary['text'][chap][sect][subsect]\n",
    "        except IndexError:\n",
    "            return \"\"\n",
    "    else:\n",
    "        try:\n",
    "            comments = commentary['text'][chap][sect]\n",
    "        except IndexError:\n",
    "            return \"\"\n",
    "    comment_text = \"%\\n\"+r\"\\comment\"+chr(comment_i+96)+\"{\"\n",
    "    blank_comment = True\n",
    "    if type(comments)==str:\n",
    "        blank_comment = False\n",
    "        comment_text = comments\n",
    "    else:\n",
    "        for comment in comments:\n",
    "            if comment == \"\":\n",
    "                continue\n",
    "            if comment[-1] == \" \":\n",
    "                comment = comment[:-1]\n",
    "            blank_comment = False\n",
    "            comment_text += comment\n",
    "#     content = chap[j-1]\n",
    "#     if type(content) == list:\n",
    "#         if content == []:\n",
    "#             return \"\"\n",
    "#         else:\n",
    "#             content = content[0]\n",
    "\n",
    "#     comment_text += content\n",
    "    comment_text += \"}%endcomment\"\n",
    "    comment_text = comment_text.replace(r\"\\par\",\"\")\n",
    "    comment_text = comment_text.replace(\"<b>\",r\"\\textrm{\\textbf{\")\n",
    "    comment_text = comment_text.replace(\"</b>\",r\"}}\")\n",
    "    if blank_comment == True:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return comment_text\n",
    "#     if \"{}\" in comment_text:\n",
    "#         return \"\"\n",
    "#     else:\n",
    "#         return comment_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_body(hebrew_text, english_text, settings, commentaries):\n",
    "    output = []\n",
    "    chap_num = 1\n",
    "    mishna_num = 1# lav davka mishna, just the smaller divisions of the text\n",
    "    title = hebrew_text[\"heTitle\"]\n",
    "    title_command = r\"\\newcommand{\\texttitle}{\"+title+\"}\"#sets title\n",
    "    try:\n",
    "        divisions_en = hebrew_text[\"sectionNames\"] #gets names of the sections for the specific text\n",
    "    except:\n",
    "        divisions_en = [\"Chapter\",\"Paragraph\"]\n",
    "        hebrew_text[\"sectionNames\"] = divisions_en\n",
    "    divisions_he = []\n",
    "    if type(hebrew_text[\"text\"])==dict:\n",
    "        hebrew_text[\"originalText\"] = hebrew_text[\"text\"]\n",
    "        hebrew_text[\"text\"] = structure_fixer(hebrew_text[\"originalText\"])\n",
    "    if english_text != None:\n",
    "        if type(english_text[\"text\"])==dict:\n",
    "            english_text[\"originalText\"] = english_text[\"text\"]\n",
    "            english_text[\"text\"] = structure_fixer(english_text[\"originalText\"])\n",
    "    #print(english_text[\"text\"])\n",
    "    #the following uses the CSV of section names to get the Hebrew sections names\n",
    "    with open('resources/section_names.csv', encoding='utf-8') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            for division in divisions_en:\n",
    "                if row[0] == division:\n",
    "                    divisions_he.append(row[1])\n",
    "    if \"Daf\" in divisions_en:\n",
    "        #if the text is based on dappim, run the script to add perakim notations\n",
    "        hebrew_text = match_chapters(hebrew_text,link_list)       \n",
    "    for perek in hebrew_text[\"text\"]:\n",
    "        if any(perek):\n",
    "            if type(perek[0]) == dict and \"name_he\" in perek[0].keys():\n",
    "                #if there's a new perek dict note, add the LaTeX code for the new perek\n",
    "                new_chap_text = r\"\\newchap{\"+parse_perek_title(perek[0])+\"}\"\n",
    "                if new_chap_text not in output:\n",
    "                    output.append(new_chap_text)\n",
    "            if \"Daf\" in divisions_en:\n",
    "                #this adds daf numbers for each new daf, ignoring the amud break\n",
    "                daf = ((chap_num+1)/2)\n",
    "                if daf == round(daf):\n",
    "                    daftitle = int_to_gematria(round(daf), gershayim=False)\n",
    "                    if settings[\"newpage\"] == 1:\n",
    "                        output.append(r\"\\clearpage\")\n",
    "                    output.append(r\"\\newsection{דף \"+daftitle+\"}\")              \n",
    "            else:\n",
    "                if settings[\"newpage\"] == 1:\n",
    "                    output.append(r\"\\clearpage\")\n",
    "                output.append(r\"\\newchap{\"+divisions_he[0]+\" \"+int_to_gematria(chap_num, gershayim=False)+\"}\")\n",
    "            for par in perek:\n",
    "                #prints next block of text\n",
    "                textblock = \"\"\n",
    "                comments = []\n",
    "                if type(par) == dict and \"name_he\" in par.keys() and par[\"name_en\"] != \"Chapter 1\":\n",
    "                    if textblock != \"\":\n",
    "                        if english_text != None and english_text[\"text\"][chap_num-1] != []:\n",
    "                            new_text = make_section(textblock,english_text[\"text\"][chap_num-1][mishna_num-1], settings, chap_num, mishna_num, commentaries)\n",
    "                        else:\n",
    "                            new_text = make_section(textblock,None, settings, chap_num, mishna_num, commentaries)\n",
    "                        output.append(new_text)\n",
    "                else:\n",
    "                    while type(par)==list:\n",
    "                        new_par = \"\"\n",
    "                        for item in par:\n",
    "                            new_par += item\n",
    "                        par = new_par\n",
    "                    if type(par) != dict:\n",
    "                        textblock += par\n",
    "                if hebrew_text[\"sectionNames\"][1] == \"Verse\" or hebrew_text[\"sectionNames\"][1] == \"Mishnah\":\n",
    "                    textblock = r\"\\vsnum{\"+str(mishna_num)+\"}\"+textblock\n",
    "                    if english_text != None:\n",
    "                        english_text[\"text\"][chap_num-1][mishna_num-1] = r\"\\vsnumeng{\"+str(mishna_num)+\"}\"+english_text[\"text\"][chap_num-1][mishna_num-1]\n",
    "                if english_text != None and english_text[\"text\"][chap_num-1] != []:\n",
    "                    new_text = make_section(textblock,english_text[\"text\"][chap_num-1][mishna_num-1], settings, chap_num, mishna_num, commentaries)\n",
    "                else:\n",
    "                    new_text = make_section(textblock,None, settings, chap_num, mishna_num, commentaries)\n",
    "                if new_text != \"\":\n",
    "                    output.append(new_text)\n",
    "                mishna_num += 1\n",
    "        chap_num += 1\n",
    "        mishna_num = 1\n",
    "    if settings[\"layout\"] == \"twocol\" and english_text == None:\n",
    "        line_i = 0\n",
    "        newsection_bool = True\n",
    "        in_cols = False\n",
    "        lastline = \"\"\n",
    "        for line in output:\n",
    "            if \"newsection\" in line or \"newchap\" in line:\n",
    "                newsection_bool = True\n",
    "                if in_cols == True:\n",
    "                    #print(\"END TWOCOLS\")\n",
    "                    if settings[\"newpage\"] < 2:\n",
    "                        end_multicols = \"\\n\"+r\"\\end{multicols}\\newpage\"+\"\\n\"\n",
    "                    else:\n",
    "                        end_multicols = \"\\n\"+r\"\\end{multicols}\"+\"\\n\"\n",
    "                    output[line_i-1] = output[line_i-1]+end_multicols\n",
    "                    in_cols = False\n",
    "            elif \"newsection\" not in line and \"newchap\" not in line and \"renewcommand\" not in line and \"fancy\" not in line:\n",
    "                if newsection_bool == True:\n",
    "                    newsection_bool = False\n",
    "                    #output[line_i] = r\"\\twocol{\"+line\n",
    "                    output[line_i] = r\"\\begin{multicols}{2}\"+\"\\n\"+line\n",
    "                    in_cols = True\n",
    "                    #print(\"BEGIN TWOCOLS\")\n",
    "\n",
    "            lastline = line\n",
    "            line_i += 1\n",
    "        #output.append(r\"}\")\n",
    "        output.append(r\"\\end{multicols}\")\n",
    "        output.append(r\"\\newpage\")\n",
    "    return title_command, output, title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_perek_title(perekDict):\n",
    "    chap_num = perekDict[\"name_en\"].replace(\"Chapter \",\"\")\n",
    "    title = r\"פרק \\hebrewnumeral{\"+chap_num+r\"} \"+perekDict[\"name_he\"]\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeformatting(text):\n",
    "    while \"<\" in text and \">\" in text:\n",
    "        loc1 = text.find(\"<\")\n",
    "        loc2 = text.find(\">\",loc1)+1\n",
    "        text = text.replace(text[loc1:loc2],\"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def footnoteremove(text):\n",
    "    if text == None:\n",
    "        return None\n",
    "    if type(text) == list:\n",
    "        print(text)\n",
    "    markbegin = \"<sup class=\\\"footnote-marker\\\">\"\n",
    "    markend = \"</sup>\"\n",
    "    while markbegin in text:\n",
    "        note_location_begin = text.find(markbegin)\n",
    "        note_location_end = text.find(markend, note_location_begin)+len(markend)\n",
    "        text = text[0:note_location_begin]+\" \"+text[note_location_end:]\n",
    "#     notebegin = \"<i class=\\\"footnote\\\">\"\n",
    "#     noteend = \"</i>\"\n",
    "#     while notebegin in text:\n",
    "#         text = text.replace(notebegin,r\" <small>(\",1)\n",
    "#         notestartloc = text.find(notebegin)\n",
    "#         noteendloc = text.find(noteend,notestartloc)\n",
    "#         while \"<i>\" in text[notestartloc:noteendloc]:\n",
    "#             next_loc = text.find(\"<i>\", noteendloc)+1\n",
    "#             next_loc = text.find(\"</i>\",next_loc)+1\n",
    "#     #text = text.replace(noteend,r\")</small> \")\n",
    "    \n",
    "#     while markbegin in text:\n",
    "#         markstart = text.find(markbegin)\n",
    "#         markend = text.find(markend,markstart)+6\n",
    "#         text = text.replace(text[markstart:markend],\"\")\n",
    "    \n",
    "    text = text.replace(\"<i class=\\\"footnote\\\">\",\"<i>\")\n",
    "    while \"<i data-\" in text:\n",
    "        note_begin = text.find(\"<i data-\")\n",
    "        note_end = text.find(\">\",note_begin+5)+1\n",
    "        note = text[note_begin:note_end]\n",
    "        text = text[0:note_begin]+\"<i>\"+text[note_end:]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_section(hebrew_text, english, settings, chap_num, mishna_num, commentaries):\n",
    "    hebrew_text = footnoteremove(hebrew_text)\n",
    "    english = footnoteremove(english)\n",
    "    with open('resources/text_replacements.csv',encoding='utf-8') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            if row[0] in hebrew_text:\n",
    "                hebrew_text = hebrew_text.replace(row[0],row[1])\n",
    "    if english != None and english != \"\":\n",
    "        with open('resources/english_replacements.csv',encoding='utf-8') as csv_file:\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            next(csv_reader)\n",
    "            for row in csv_reader:\n",
    "                if row[0] in english:\n",
    "                    english = english.replace(row[0],row[1])\n",
    "    #turns a block of text into a latex section using the \\textblock or \\twocol command\n",
    "    if english != \"\" and english != None:\n",
    "        english = english.replace(\"[\",\"{[\")\n",
    "        english = english.replace(\"]\",\"]}\")\n",
    "        output = r\"\\hebeng{\"+hebrew_text+\"}{\"+english+\"}\"\n",
    "        if settings[\"newpage\"] == 1:\n",
    "            output += r\"\\newpage\"\n",
    "    elif settings[\"layout\"] == \"twocol\":\n",
    "        #output= r\"\\twocol{\"+hebrew_text+\"}\"\n",
    "        output = hebrew_text\n",
    "    elif hebrew_text==\"\":\n",
    "        output = \"\"\n",
    "    else:\n",
    "        output= r\"\\textblock{\"+hebrew_text+\"}\"\n",
    "    comment_i = 1\n",
    "    for commentary in commentaries:\n",
    "        #output+=\"\\n\"\n",
    "        output+=get_comments(chap_num,mishna_num,commentary,comment_i)\n",
    "        comment_i += 1\n",
    "    output = removeformatting(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this adds commands for part-specific formatting\n",
    "#it outputs a list of lines to be written to the beginning of that part\n",
    "#basically duplicates the formatting commands for the overall document\n",
    "def add_part_format(part_i, settings):\n",
    "    output = []\n",
    "    part_settings = settings[\"texts\"][part_i][\"format\"]\n",
    "    if \"hebfont\" in part_settings.keys():\n",
    "        font = r\"\\setmainfont{\"+part_settings[\"hebfont\"]+r\"}\"\n",
    "    else:\n",
    "        font = r\"\\setmainfont{\"+settings[\"hebfont\"]+r\"}\"\n",
    "    output.append(font)\n",
    "    if \"commentfont\" in part_settings.keys():\n",
    "        commentfont = part_settings[\"commentfont\"]\n",
    "    elif settings[\"commentfont\"]!=\"\":\n",
    "        commentfont = settings[\"commentfont\"]\n",
    "    else:\n",
    "        commentfont = settings[\"hebfont\"]\n",
    "    comment_command = r\"\\setsansfont{\"+commentfont+\"}\"\n",
    "    output.append(comment_command)\n",
    "    output = []\n",
    "\n",
    "    if settings[\"headpos\"] == \"center\":\n",
    "        odd_header = r\"\\fancyhead[CO]{\"\n",
    "        even_header = r\"\\fancyhead[CE]{\"\n",
    "    elif settings[\"headpos\"] == \"inner\":\n",
    "        odd_header = r\"\\fancyhead[RO]{\"\n",
    "        even_header = r\"\\fancyhead[LE]{\"\n",
    "    if \"evenhead\" in part_settings.keys():\n",
    "        evenhead = part_settings[\"evenhead\"]\n",
    "    else:\n",
    "        evenhead = settings[\"evenhead\"]\n",
    "    if \"oddhead\" in part_settings.keys():\n",
    "        oddhead = part_settings[\"oddhead\"]\n",
    "    else:\n",
    "        oddhead = settings[\"oddhead\"]\n",
    "    if evenhead == \"title\":\n",
    "        even_header += r\"\\partname\"\n",
    "    elif evenhead == \"chapter\":\n",
    "        even_header += r\"\\chapname\"\n",
    "    elif evenhead == \"titlechapter\":\n",
    "        even_header += r\"\\partname\\space\\textendash\\space \\chapname\"\n",
    "    elif evenhead == \"daf\":\n",
    "        even_header += r\"\\sectname\"\n",
    "    elif evenhead == \"chapdaf\":\n",
    "        even_header += r\"\\chapname \\space\\textendash\\space \\sectname\"\n",
    "    if oddhead == \"title\":\n",
    "        odd_header += r\"\\partname\"\n",
    "    elif oddhead == \"chapter\":\n",
    "        odd_header += r\"\\chapname\"\n",
    "    elif oddhead == \"titlechapter\":\n",
    "        odd_header += r\" \\partname\\space\\textendash\\space \\chapname\"\n",
    "    elif oddhead == \"daf\":\n",
    "        odd_header += r\"\\sectname\"\n",
    "    elif oddhead == \"chapdaf\":\n",
    "        odd_header += r\"\\chapname \\space\\textendash\\space \\sectname\"\n",
    "    odd_header += \"}\"\n",
    "    even_header += \"}\"\n",
    "    output.append(odd_header)\n",
    "    output.append(even_header)\n",
    "\n",
    "    if \"fontsize\" in part_settings.keys():\n",
    "        fontsize = part_settings[\"fontsize\"]\n",
    "    else:\n",
    "        fontsize = settings[\"fontsize\"]\n",
    "    if \"spacing\" in part_settings.keys():\n",
    "        skip = fontsize * part_settings[\"spacing\"]\n",
    "    else:\n",
    "        skip = fontsize * settings[\"spacing\"]\n",
    "    if \"engfontsize\"in part_settings.keys():\n",
    "        engsize = part_settings[\"engfontsize\"]\n",
    "    elif \"engfontsize\" in settings.keys():\n",
    "        engsize = settings[\"engfontsize\"]\n",
    "    else:\n",
    "        engsize = settings[\"fontsize\"]\n",
    "    fontsizestr = r\"\\renewcommand{\\sethebfont}{\\fontsize{\"+str(fontsize)+r\"pt}{\"+str(round(skip,1))+r\"pt} \\selectfont}\\sethebfont\"\n",
    "    engsizestr = r\"\\renewcommand{\\setengfont}{\\fontsize{\"+str(engsize)+r\"pt}{\"+str(round(skip,1))+r\"pt} \\selectfont}\\setengfont\"\n",
    "    output.append(fontsizestr)\n",
    "    output.append(engsizestr)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments(i,j,commentary,comment_i):\n",
    "    try:\n",
    "        chap = commentary[\"text\"][i-1]\n",
    "    except IndexError:\n",
    "        return \"\"\n",
    "    if len(chap)<j:\n",
    "        return \"\"\n",
    "    #command_name = r\"\\comment_\"+str(comment_i)\n",
    "    comment_text = \"%\\n\"+r\"\\comment\"+chr(comment_i+96)+\"{\"\n",
    "#     for comment in chap[j-1]:\n",
    "#         if comment == \"\":\n",
    "#             continue\n",
    "#         if comment[-1] == \" \":\n",
    "#             comment = comment[:-1]\n",
    "#         comment_text += comment\n",
    "    content = chap[j-1]\n",
    "    if type(content) == list:\n",
    "        if content == []:\n",
    "            return \"\"\n",
    "        else:\n",
    "            content = content[0]\n",
    "    content = content.replace(r\"\\par\",\"\")\n",
    "    content = content.replace(\"<b>\",r\"\\textrm{\\textbf{\")\n",
    "    content = content.replace(\"</b>\",r\"}}\")\n",
    "    comment_text += content\n",
    "    comment_text += \"}%endcomment\"\n",
    "    #comment_text = comment_text.replace(r\"\\quad }\",\"}\")\n",
    "    if \"{}\" in comment_text:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return comment_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_fixer(json):\n",
    "    if type(json) is list:\n",
    "        return json\n",
    "    text = []\n",
    "    titles = []\n",
    "    for part in json.values():\n",
    "        if type(part) is list:\n",
    "            text.append(part)\n",
    "        elif type(part) is dict:\n",
    "            text_part = []\n",
    "            for subpart in part.values():\n",
    "                if type(subpart) is list:\n",
    "                    text_part.append(subpart)\n",
    "                elif type(subpart) is dict:\n",
    "                    text_subpart = []\n",
    "                    for subsubpart in subpart.values():\n",
    "                        if type(subsubpart) is list:\n",
    "                            text_subpart.append(subsubpart)\n",
    "                    text_part.append(text_subpart)\n",
    "            text.append(text_part)\n",
    "            #print(part)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = pull_text(\"Halakhah/Acharonim/Chofetz Chaim/Hebrew/Chofetz Chaim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#structure_fixer(test[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_format(template_lines,settings):\n",
    "    output = []\n",
    "    #this sets the format for the text in the LaTeX preamble.\n",
    "    #ths line[0:-1] is the text of the line in LaTeX being converted by the script.\n",
    "    #the -1 is needed to exclude the \\n for line break at the end of each line.\n",
    "    #these work by converting a LaTeX comment for a specific formatting piece to a command, based on what's in the settings json.\n",
    "    if len(settings[\"texts\"])>1:\n",
    "        titlehead = r\"\\partname\"\n",
    "    else:\n",
    "        titlehead = r\"\\texttitle\"\n",
    "    for line in template_lines:\n",
    "        if line[0:-1] in settings.keys():\n",
    "            setting_output = line[0:-1] + \"=\"+settings[line[0:-1]]+\",\\n\"\n",
    "            output.append(setting_output)\n",
    "        elif line[0:-1] == \"%setfontsize\":\n",
    "            fontsize = settings[\"fontsize\"]\n",
    "            skip = fontsize * settings[\"spacing\"]\n",
    "            fontsizestr = r\"\\fontsize{\"+str(fontsize)+r\"pt}{\"+str(round(skip,1))+r\"pt} \\selectfont\"\n",
    "            output.append(fontsizestr)\n",
    "        elif line[0:-1] == \"%engfontsize\":\n",
    "            if \"engfontsize\" in settings.keys():\n",
    "                fontsize = settings[\"engfontsize\"]\n",
    "            else:\n",
    "                fontsize = settings[\"fontsize\"]\n",
    "            skip = fontsize * settings[\"spacing\"]\n",
    "            fontsizestr = r\"\\fontsize{\"+str(fontsize)+r\"pt}{\"+str(round(skip,1))+r\"pt} \\selectfont\"\n",
    "            output.append(fontsizestr)\n",
    "        elif line[0:-1] == \"%sethebfont\":\n",
    "            if settings[\"hebboldfont\"] == \"\":\n",
    "                font = r\"\\setmainfont{\"+settings[\"hebfont\"]+r\"}\"\n",
    "            else:\n",
    "                font = r\"\\setmainfont[BoldFont = {\"+settings[\"hebboldfont\"]+r'}]{'+settings[\"hebfont\"]+r\"}\"\n",
    "            output.append(font)\n",
    "        elif line[0:-1] == \"%setcommentfont\":\n",
    "            if \"commentfont\" in settings.keys():\n",
    "                font = r\"\\setsansfont{\"+settings[\"commentfont\"]+\"}\"\n",
    "                output.append(font)\n",
    "        elif line[0:-1] == \"%setengfont\" and settings[\"engfont\"] != 0:\n",
    "            engfont = r'\\newfontfamily\\englishfont{'+settings[\"engfont\"]+r'}'\n",
    "            output.append(engfont)\n",
    "        elif line[0:-1] == \"%setparskip\" and settings[\"parskip\"] != 0:\n",
    "            parskip = r'\\setlength{\\parskip}{'+settings[\"parskip\"]+'}'\n",
    "            output.append(parskip)\n",
    "        elif line[0:-1] == \"%pagenumber\":\n",
    "            if settings[\"pagenumloc\"] == \"topouter\":\n",
    "                pagenum = r\"\\fancyhead[LO,RE]{num}\"\n",
    "            elif settings[\"pagenumloc\"] == \"bottommiddle\":\n",
    "                pagenum = r\"\\fancyfoot[C]{num}\"\n",
    "            if settings[\"pagenumheb\"] == True:\n",
    "                pagenum = pagenum.replace(\"num\",r\"\\hebrewnumeral{\\thepage}\")\n",
    "            else:\n",
    "                pagenum = pagenum.replace(\"num\",r\"\\thepage\")\n",
    "            output.append(pagenum)\n",
    "        elif line[0:-1] == \"%header\":\n",
    "            if settings[\"headpos\"] == \"center\":\n",
    "                odd_header = r\"\\fancyhead[CO]{\"\n",
    "                even_header = r\"\\fancyhead[CE]{\"\n",
    "            elif settings[\"headpos\"] == \"inner\":\n",
    "                odd_header = r\"\\fancyhead[RO]{\"\n",
    "                even_header = r\"\\fancyhead[LE]{\"\n",
    "            if settings[\"evenhead\"] == \"title\":\n",
    "                even_header += titlehead\n",
    "            elif settings[\"evenhead\"] == \"chapter\":\n",
    "                even_header += r\"\\chapname\"\n",
    "            elif settings[\"evenhead\"] == \"titlechapter\":\n",
    "                even_header += titlehead + r\" \\space\\textendash\\space \\chapname\"\n",
    "            elif settings[\"evenhead\"] == \"daf\":\n",
    "                even_header += r\"\\sectname\"\n",
    "            elif settings[\"evenhead\"] == \"chapdaf\":\n",
    "                even_header += r\"\\chapname \\space\\textendash\\space \\sectname\"\n",
    "            if settings[\"oddhead\"] == \"title\":\n",
    "                odd_header += titlehead\n",
    "            elif settings[\"oddhead\"] == \"chapter\":\n",
    "                odd_header += r\"\\chapname\"\n",
    "            elif settings[\"oddhead\"] == \"titlechapter\":\n",
    "                odd_header += titlehead + r\" \\space\\textendash\\space \\chapname\"\n",
    "            elif settings[\"oddhead\"] == \"daf\":\n",
    "                even_header += r\"\\sectname\"\n",
    "            elif settings[\"oddhead\"] == \"chapdaf\":\n",
    "                even_header += r\"\\chapname \\space\\textendash\\space \\sectname\"\n",
    "            \n",
    "            odd_header += \"}\"\n",
    "            even_header += \"}\"\n",
    "            output.append(odd_header)\n",
    "            output.append(even_header)\n",
    "        elif line[0:-1] == \"%chapfontsize\":\n",
    "            if \"chapfontsize\" in settings.keys():\n",
    "                headerfontcommand = r\"\\fontsize{\"+settings[\"chapfontsize\"]+\"}{\"+settings[\"chapfontsize\"]+r\"}\\selectfont\"\n",
    "            else:\n",
    "                headerfontcommand = r\"\\LARGE\"\n",
    "            output.append(headerfontcommand)\n",
    "        elif line[0:-1] == \"%setcolumnsep\":\n",
    "            output.append(r\"\\setlength{\\columnsep}{\"+settings[\"colsep\"]+\"}\")\n",
    "        elif line[0:-1] == \"%twocolfootnote\" and settings[\"twocolfootnotes\"] == 1:\n",
    "            output.append(r\"\\usepackage{dblfnote}\\DFNalwaysdouble\")\n",
    "        else:\n",
    "            output.append(line)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bib_info(json):\n",
    "    #puts bibliographic info in a dict\n",
    "    source_data = {}\n",
    "    source_data[\"source\"] = json[\"versionSource\"]\n",
    "    if \"license\" in json.keys():\n",
    "        source_data[\"license\"] = json[\"license\"]\n",
    "    else:\n",
    "        source_data[\"license\"] = \"CC-BY\"\n",
    "    source_data[\"version\"] = json[\"versionTitle\"]\n",
    "    source_data[\"heTitle\"] = json[\"heTitle\"]\n",
    "    return source_data\n",
    "\n",
    "def print_source_data(source_list):\n",
    "    output = []\n",
    "    output.append(r\"\\begin{itemize}\")\n",
    "    #puts every piece of bibliographic info into a copyright notice\n",
    "    for source in source_list:\n",
    "        if \"Copyright\" in source[\"license\"]:\n",
    "            return [\"NC\",source[\"version\"]]\n",
    "        if \"NC\" in source[\"license\"]:\n",
    "            print(\"A source selected has a non-commercial license.\\nDo not use the PDF version of this text commercially.\")\n",
    "        versiontitle = source[\"version\"].replace(\"-\",r\"\\textendash \")\n",
    "        output.append(r\"\\item[$\\bullet$] \"+versiontitle)\n",
    "        if len(source_list) > 1:\n",
    "            output.append(r\"\\begin{itemize}\")\n",
    "        output.append(r\"\\item[$\\bullet$] License: \"+source[\"license\"])\n",
    "        output.append(r\"\\item[$\\bullet$] Source: \\url{\"+source[\"source\"]+\"}\")\n",
    "        if len(source_list) > 1:\n",
    "            output.append(r\"\\end{itemize}\")\n",
    "    output.append(r\"\\end{itemize}\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reads template file\n",
    "inputpath = os.path.join(\"resources\",\"input.tex\")\n",
    "coverinpath = os.path.join(\"resources\",\"input_cover.tex\")\n",
    "def pullinput(inputpath):\n",
    "    with open(inputpath, 'r', encoding='utf-8') as infile:\n",
    "        template_lines = list(infile.readlines())\n",
    "    return template_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this limits the input to the specific range specified in the text settings\n",
    "def limit_output(lines,textsettings):\n",
    "    if \"dafrange\" in textsettings.keys():\n",
    "        start_end = textsettings[\"dafrange\"].split(\"-\")\n",
    "        start = int_to_gematria(start_end[0], gershayim=False)\n",
    "        end = int_to_gematria(start_end[1], gershayim=False)\n",
    "        content = False\n",
    "        limited_lines = []\n",
    "        for line in lines:\n",
    "            if content == False and r\"\\newsection{דף \"+start in line:\n",
    "                content = True\n",
    "                limited_lines.append(line)\n",
    "            elif content == True and r\"\\newsection{דף \"+end in line:\n",
    "                content = False\n",
    "                for line in limited_lines:\n",
    "                    if r\"\\newsection{דף \" in line:\n",
    "                        line = line.replace(r\"\\newsection{דף \", r\"\\newchap{דף \")\n",
    "                return limited_lines\n",
    "            elif content == True:\n",
    "                limited_lines.append(line)\n",
    "            else:\n",
    "                continue\n",
    "    elif textsettings[\"range\"] == \"all\" or \"range\" not in textsettings.keys():\n",
    "        return lines\n",
    "    else:\n",
    "        array = range_str(textsettings[\"range\"])\n",
    "        sorted_lines = []\n",
    "        limited_lines = []\n",
    "        onechap = []\n",
    "        for line in lines:\n",
    "            if \"newchap\" not in line:\n",
    "                onechap.append(line)\n",
    "            else:\n",
    "                sorted_lines.append(onechap)\n",
    "                onechap = [line]\n",
    "        for chap in array:\n",
    "            for line in sorted_lines[chap]:\n",
    "                limited_lines.append(line)\n",
    "        return limited_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this parses the string describing the range\n",
    "def range_str(string):\n",
    "    rng_array = []\n",
    "    ranges = string.split(\",\")\n",
    "    for numbers in ranges:\n",
    "        if \"-\" not in numbers:\n",
    "            rng_array.append(int(numbers))\n",
    "        else:\n",
    "            start_end = numbers.split(\"-\")\n",
    "            start = int(start_end[0])\n",
    "            end = int(start_end[1])\n",
    "            for number in range(start,end+1):\n",
    "                rng_array.append(number)\n",
    "    return rng_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#when \"blockcomment\" is selected, moves comments to the end of the perek\n",
    "def move_comments(lines, title, newpage):\n",
    "    collected_comments = []\n",
    "    output = []\n",
    "    i=1\n",
    "    for line in lines:\n",
    "        if r\"\\comment\" in line:\n",
    "            comment_start = line.index(r\"\\comment\")+10\n",
    "            comment_end = line.index(\"}%endcomment\")\n",
    "            comment = line[comment_start:comment_end]\n",
    "            line = line[:comment_start-10]+line[comment_end+12:]\n",
    "            output.append(line)\n",
    "            collected_comments.append(comment)\n",
    "        elif r\"\\newchap\" in line or r\"\\newsection\" in line or r\"\\addpart\" in line:\n",
    "            if collected_comments != []:\n",
    "                comments_str = r\"\\blockcomment{\"+title+\"}{\"\n",
    "                for comment in collected_comments:\n",
    "                    comments_str += comment+r\"\\\\\"\n",
    "                comments_str += \"\\n}%endcomment\"\n",
    "                if newpage == 1:\n",
    "                    comments_str += r\"\\newpage\"\n",
    "                output = output + [comments_str] + [line]\n",
    "                collected_comments = []\n",
    "            else:\n",
    "                output.append(line)\n",
    "        else:\n",
    "            output.append(line)\n",
    "    if collected_comments != []:\n",
    "        comments_str = r\"\\blockcomment{\"+title+\"}{\"\n",
    "        for comment in collected_comments:\n",
    "            comments_str += comment+r\"\\\\\"\n",
    "        comments_str += r\"\\n}%endcomment\"\n",
    "        if newpage == 1:\n",
    "            comments_str += r\"\\newpage\"\n",
    "        output = output + [comments_str]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_fix(text):\n",
    "    for i in range(1,len(text)):\n",
    "        if r\"\\blockcomment{\" in text[i] and text[i-1][0:-1] == r\"\\clearpage}\":\n",
    "                text[i-1] = \"}\\n\"\n",
    "        if \"}%endcomment\" in text[i]:\n",
    "            text[i] = text[i].replace(\"}%endcomment\",\"}\\clearpage %endcomment\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converts input into output\n",
    "def writeoutput(outputpath, template, formatting):\n",
    "    sources = []\n",
    "    parts = []\n",
    "    template_with_settings = set_format(template,formatting)#reads settings\n",
    "    for text in formatting[\"texts\"]:\n",
    "        if \"translation\" not in text.keys():\n",
    "            text[\"translation\"] = \"\"\n",
    "        if \"range\" not in text.keys():\n",
    "            text[\"range\"] = \"all\"\n",
    "        part_format = text[\"format\"]\n",
    "        #print(part_format)\n",
    "        for setting in formatting.items():\n",
    "            if setting[0] not in part_format.keys() and setting[0] != \"texts\":\n",
    "         #       print(setting)\n",
    "                part_format[setting[0]] = setting[1]\n",
    "        if part_format[\"layout\"]==\"twocol\":\n",
    "            part_format[\"newpage\"] = 0\n",
    "        #print(part_format)\n",
    "        sefaria_json = pull_text(text[\"link\"])#pulls json from Sefaria\n",
    "        bib_data = get_bib_info(sefaria_json)\n",
    "        sources.append(bib_data)#puts bibliographic info in sources list\n",
    "        commentaries = []\n",
    "        for commentary in text[\"commentary\"]:\n",
    "            comments_json = pull_text(commentary)\n",
    "            bib_data = get_bib_info(comments_json)\n",
    "            commentary_title = bib_data[\"heTitle\"]\n",
    "            sources.append(bib_data)\n",
    "            commentaries.append(comments_json)\n",
    "        if text[\"translation\"]!= \"\":\n",
    "            #pulls translation, if any, and adds to bibliographic list\n",
    "            english_json = pull_text(text[\"translation\"])\n",
    "            sources.append(get_bib_info(english_json))\n",
    "            if type(sefaria_json[\"text\"]) == dict:\n",
    "                sefaria_result = make_body_json(sefaria_json,english_json,part_format,commentaries)\n",
    "            else:\n",
    "                sefaria_result = make_body(sefaria_json,english_json,part_format,commentaries)\n",
    "        else:\n",
    "            if type(sefaria_json[\"text\"]) == dict:\n",
    "                sefaria_result = make_body_json(sefaria_json,None,part_format,commentaries)\n",
    "            else:\n",
    "                sefaria_result = make_body(sefaria_json,None,part_format,commentaries)\n",
    "#         print(sefaria_result[1])\n",
    "        content_limited = limit_output(sefaria_result[1],text)\n",
    "\n",
    "        if part_format[\"commentstyle\"] == \"blocks\" and text[\"commentary\"] != []:\n",
    "            content_limited = move_comments(content_limited, commentary_title, formatting[\"newpage\"])\n",
    "            if part_format[\"newpage\"] == 1:\n",
    "                content_limited = block_fix(content_limited)\n",
    "        part = {\"title\":sefaria_result[2],\"content\":content_limited}\n",
    "        parts.append(part)\n",
    "#         parts.append(sefaria_result[1])\n",
    "#         titles.append(sefaria_result[2])\n",
    "#         title_command = sefaria_result[0]\n",
    "        source_listing = print_source_data(sources)\n",
    "        if source_listing[0] == \"NC\":#stops the script if the license doesn't allow the text to run\n",
    "            print(source_listing[1] + \" has a license which does not allow creation of this text.\")\n",
    "            return\n",
    "    title_command = r\"\\newcommand{\\texttitle}{\"+formatting[\"titleheb\"]+\"}\"\n",
    "    with open(outputpath, 'w', encoding='utf-8') as outfile:#, open(\"test.txt\",'w',encoding='utf-8') as testfile:\n",
    "        for line in template_with_settings:\n",
    "            if line == \"%title_here\\n\":\n",
    "                outfile.write(title_command)\n",
    "            elif line == \"%license info\\n\":\n",
    "                for item in source_listing:\n",
    "                    outfile.write(item)\n",
    "                    outfile.write(\"\\n\")\n",
    "            elif line == \"%body_here\\n\":\n",
    "                if len(parts) == 1:\n",
    "                    for newline in parts[0][\"content\"]:\n",
    "                        if newline[-1]==\" \":\n",
    "                            newline = newline[0:-1]\n",
    "                        outfile.write(newline+\"\\n\")\n",
    "                        #testfile.write(newline+\"\\n\")\n",
    "                elif len(parts)>1:\n",
    "                    part_num = 0\n",
    "                    for part in parts:\n",
    "                        outfile.write(r\"\\addpart{\"+part[\"title\"]+r\"}\\renewcommand{\\partname}[1]{\"+part[\"title\"]+\"}\\n\")                       \n",
    "                        part_format = add_part_format(part_num,formatting)\n",
    "                        #part_format = []\n",
    "                        for line in part_format:\n",
    "                            outfile.write(line+\"\\n\")\n",
    "                        for newline in part[\"content\"]:\n",
    "                            outfile.write(newline+\"\\n\")\n",
    "                            #testfile.write(newline+\"\\n\")\n",
    "                        part_num += 1\n",
    "            else:\n",
    "                outfile.write(line)\n",
    "                if \"\\n\" not in line:\n",
    "                    outfile.write(\"\\n\")\n",
    "    cover_title_heb = title_to_cover(title_command)\n",
    "    #eng_title_cover = \n",
    "    if \"title\" in formatting.keys():\n",
    "         return formatting[\"title\"]\n",
    "    else:\n",
    "        return cover_title_heb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cover(outputpath,cover_template,title,settings,pages):\n",
    "    coverOutPath = outputpath.replace(\".tex\",\"_cover.tex\")\n",
    "    inches = calc_spine_width(pages,settings)\n",
    "    with open(coverOutPath,'w',encoding='utf-8') as outfile:\n",
    "        for line in cover_template:\n",
    "            if line == \"%hebtitle\\n\":\n",
    "                outfile.write(title)\n",
    "            elif line == \"%backgroundcolor\\n\":\n",
    "                background_command = r\"\\definecolor{background}{HTML}{\"+settings[\"covercolor\"]+\"}\"\n",
    "                outfile.write(background_command+\"\\n\")\n",
    "            elif line == \"%textcolor\\n\":\n",
    "                text_command = r\"\\definecolor{text}{HTML}{\"+settings[\"covertextcolor\"]+\"}\"\n",
    "                outfile.write(text_command+\"\\n\")\n",
    "            elif line == \"%height\\n\":\n",
    "                if settings[\"covertype\"] == \"hardcover\":\n",
    "                    pageheight = float(settings[\"paperheight\"].replace(\"in\",\"\"))+1.5\n",
    "                elif settings[\"covertype\"] == \"softcover\":\n",
    "                    pageheight = float(settings[\"paperheight\"].replace(\"in\",\"\"))\n",
    "                coverheight = \"coverheight=\"+str(pageheight)+\"in,\\n\"\n",
    "                outfile.write(coverheight)\n",
    "            elif line == \"%width\\n\":\n",
    "                if settings[\"covertype\"] == \"hardcover\":\n",
    "                    pagewidth = float(settings[\"paperwidth\"].replace(\"in\",\"\"))+.75\n",
    "                elif settings[\"covertype\"] == \"softcover\":\n",
    "                    pagewidth = float(settings[\"paperwidth\"].replace(\"in\",\"\"))\n",
    "                coverwidth = \"coverwidth=\"+str(pagewidth)+\"in,\\n\"\n",
    "                outfile.write(coverwidth)\n",
    "            elif line == \"%spinewidth\\n\":\n",
    "                outfile.write(\"spinewidth=\"+str(inches)+\"in,\\n\")\n",
    "            elif line == \"%bleedwidth\\n\":\n",
    "#                 if settings[\"covertype\"] == \"hardcover\":\n",
    "                outfile.write(\"bleedwidth=.125in,\\n\")\n",
    "#                 elif settings[\"covertype\"] == \"softcover\":\n",
    "#                     outfile.write(\"bleedwidth=0in,\\n\")\n",
    "            elif \"%spinetextheight\" in line:\n",
    "                spine_txt_ht = min(float(inches),0.375)\n",
    "                inches_spine_text = str(0.85 * spine_txt_ht)\n",
    "                spine_ht_command = r\"\\fontsize{\"+inches_spine_text+\"in}{\"+inches_spine_text+\"in}\\selectfont\"\n",
    "                outfile.write(spine_ht_command)\n",
    "            elif \"%backtext\" in line:\n",
    "                if \"backtext\" in settings.keys():\n",
    "                    outfile.write(settings[\"backtext\"])\n",
    "            elif \"%sethebfont\" in line:\n",
    "                font = r\"\\setmainfont{\"+settings[\"hebfont\"]+r\"}\"\n",
    "                outfile.write(font)\n",
    "            elif \"%setengfont\" in line:\n",
    "                engfont = r'\\newfontfamily\\englishfont{'+settings[\"engfont\"]+r'}'\n",
    "                outfile.write(engfont)\n",
    "            else:\n",
    "                outfile.write(line)\n",
    "                if \"\\n\" not in line:\n",
    "                    outfile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_spine_width(pages,settings):\n",
    "    if settings[\"covertype\"]==\"softcover\":\n",
    "        return (pages / 444) + 0.06\n",
    "    elif settings[\"covertype\"]==\"hardcover\":\n",
    "        with open('resources/spine_width.csv', encoding='utf-8') as csv_file:\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            spine_width = 0\n",
    "            for row in csv_reader:\n",
    "                if int(row[0])<=pages<=int(row[1]):\n",
    "                    return row[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_to_cover(heb_title):\n",
    "    heb_title = heb_title[24:-1]\n",
    "    heb_title_cover_list = heb_title.split()[::-1]\n",
    "    title_for_cover_heb = \"\"\n",
    "    for word in heb_title_cover_list:\n",
    "        title_for_cover_heb += word + ' '\n",
    "    title_for_cover_heb = title_for_cover_heb[0:-1]\n",
    "    return title_for_cover_heb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flips PDF for print on demand\n",
    "def flip_PDF(inpfn):\n",
    "    rotate = 180\n",
    "    #ranges = [[int(y) for y in x.split('-')] for x in ranges]\n",
    "    outname = inpfn.split(\".pdf\")\n",
    "    outfn = outname[0]+\".rotated.\"+outname[1]+\"pdf\"\n",
    "#     print(outfn)\n",
    "    #outfn = 'rotate.%s' % os.path.basename(inpfn)\n",
    "    trailer = PdfReader(inpfn)\n",
    "    pages = trailer.pages\n",
    "\n",
    "    ranges = [[1, len(pages)]]\n",
    "\n",
    "    for onerange in ranges:\n",
    "        onerange = (onerange + onerange[-1:])[:2]\n",
    "        for pagenum in range(onerange[0]-1, onerange[1]):\n",
    "            pages[pagenum].Rotate = (int(pages[pagenum].inheritable.Rotate or\n",
    "                                         0) + rotate) % 360\n",
    "\n",
    "    outdata = PdfWriter(outfn)\n",
    "    outdata.trailer = trailer\n",
    "    outdata.write()\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_latex(outputname):\n",
    "    subprocess.run(['xelatex', '-interaction=nonstopmode', outputname], shell=True)\n",
    "    subprocess.run(['xelatex', '-interaction=nonstopmode', outputname], shell=True)\n",
    "    pdf_name = outputname.replace(\".tex\",\".pdf\")\n",
    "    flip_PDF(pdf_name)\n",
    "    pages = len(PdfReader(pdf_name).pages)\n",
    "    if pages < 24 and book_settings[\"covertype\"] == \"hardcover\":\n",
    "        print(\"Hardcover books shorter than 24 pages cannot be printed on demand\")\n",
    "    elif pages >= 800:\n",
    "        print(\"Warning: PDF output is over 800 pages, which is too long for print-on-demand.\")\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://raw.githubusercontent.com/Sefaria/Sefaria-Export/master/json/Jewish%20Thought/Acharonim/Maharal/Gevurot%20Hashem/Hebrew/Gevurot%20Hashem,%20with%20footnotes%20and%20annotations%20by%20Rabbi%20Yehoshua%20D.%20Hartman,%20Machon%20Yerushalyim,%202015-2020.json\n",
      "https://raw.githubusercontent.com/Sefaria/Sefaria-Export/master/json/Jewish%20Thought/Acharonim/Maharal/Notes%20by%20Rabbi%20Yehoshua%20Hartman%20on%20Gevurot%20Hashem/Hebrew/Gevurot%20Hashem,%20with%20footnotes%20and%20annotations%20by%20Rabbi%20Yehoshua%20D.%20Hartman,%20Machon%20Yerushalyim,%202015-2020.json\n",
      "A source selected has a non-commercial license.\n",
      "Do not use the PDF version of this text commercially.\n"
     ]
    }
   ],
   "source": [
    "template_lines = pullinput(inputpath)\n",
    "# for line in template_lines:\n",
    "#     print(line)\n",
    "outputname = \"output.tex\"\n",
    "with open('book_settings(4).json',encoding='utf=8') as json_file:\n",
    "    book_settings = json.load(json_file)\n",
    "title_heb = writeoutput(outputname,template_lines,book_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputname = \"output.tex\"\n",
    "pages = compile_latex(outputname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "covertemplate = pullinput(coverinpath)\n",
    "make_cover(outputname,covertemplate,title_heb,book_settings,pages)\n",
    "coveroutputname = outputname.replace(\".tex\",\"_cover.tex\")\n",
    "subprocess.run(['xelatex', '-interaction=nonstopmode', coveroutputname])\n",
    "flip_PDF(coveroutputname.replace(\".tex\",\".pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
