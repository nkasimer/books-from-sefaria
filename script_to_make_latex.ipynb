{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pylatex\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/76/015a1d785221d9b0d2ad80759d892a6d9d0a8a05daffc52202311ea3d652/PyLaTeX-1.4.1.tar.gz (84kB)\n",
      "Collecting ordered-set (from pylatex)\n",
      "  Downloading https://files.pythonhosted.org/packages/f5/ab/8252360bfe965bba31ec05112b3067bd129ce4800d89e0b85613bc6044f6/ordered-set-4.0.2.tar.gz\n",
      "Building wheels for collected packages: pylatex, ordered-set\n",
      "  Building wheel for pylatex (setup.py): started\n",
      "  Building wheel for pylatex (setup.py): finished with status 'done'\n",
      "  Created wheel for pylatex: filename=PyLaTeX-1.4.1-cp37-none-any.whl size=42829 sha256=c5f9b218136444d7f78848b537d394b47930d4f9495c22f1c67e2e5e3b290c8c\n",
      "  Stored in directory: C:\\Users\\nkasimer\\AppData\\Local\\pip\\Cache\\wheels\\a2\\25\\3a\\2cc0a6219d95ce34f1f7439a6427c62ca262ebaeb5969db89f\n",
      "  Building wheel for ordered-set (setup.py): started\n",
      "  Building wheel for ordered-set (setup.py): finished with status 'done'\n",
      "  Created wheel for ordered-set: filename=ordered_set-4.0.2-py2.py3-none-any.whl size=8213 sha256=505a57efc984cbff79d668e85616bd4abf88c658513658a594968c07c0fbba81\n",
      "  Stored in directory: C:\\Users\\nkasimer\\AppData\\Local\\pip\\Cache\\wheels\\e1\\c6\\9b\\651d8a21d59b51a75ab9c070838f9231b8126421bc0569af47\n",
      "Successfully built pylatex ordered-set\n",
      "Installing collected packages: ordered-set, pylatex\n",
      "Successfully installed ordered-set-4.0.2 pylatex-1.4.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pylatex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, urllib.request\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "import os, platform, subprocess, csv\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_text(string_for_link):\n",
    "    link = \"https://raw.githubusercontent.com/Sefaria/Sefaria-Export/master/json/\"+string_for_link+\".json\"\n",
    "    print(link)\n",
    "    with urllib.request.urlopen(link) as url:\n",
    "        text_json = json.loads(url.read().decode())\n",
    "    return text_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_links():\n",
    "    link_list = []\n",
    "    for i in range(9):\n",
    "        with open('links/links'+str(i)+'.csv', encoding=\"utf-8\") as csv_file:\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            next(csv_reader)\n",
    "            for row in csv_reader:\n",
    "                if row[2] == \"commentary\":\n",
    "                    link = []\n",
    "                    link.append(row[0])\n",
    "                    link.append(row[1])\n",
    "                    link_list.append(link)\n",
    "    return link_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_list = pull_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_comment(comment_str, links):\n",
    "    for link in links:\n",
    "        if comment_str in link[0]:\n",
    "            return link[1]\n",
    "        elif comment_str in link[1]:\n",
    "            return link[0]\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_json(masekhet):\n",
    "    link = \"https://raw.githubusercontent.com/Sefaria/Sefaria-Export/master/schemas/\"+masekhet+\".json\"\n",
    "    with urllib.request.urlopen(link) as url:\n",
    "        index_json = json.loads(url.read().decode())\n",
    "    chaps = index_json[\"alts\"][\"Chapters\"][\"nodes\"]\n",
    "    return chaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_perek(name):\n",
    "    name = name.split(' ')\n",
    "    masekhet = name[0]\n",
    "    daf,line = name[1].split(\":\")\n",
    "    chapters = get_index_json(masekhet)\n",
    "    ref = masekhet+\" \"+daf\n",
    "    for chapter in chapters:\n",
    "        for page in chapter[\"refs\"]:\n",
    "            if \":\" not in page and page==ref:\n",
    "                return chapter[\"title\"],chapter['heTitle']\n",
    "            elif \":\" in page and ref in page:\n",
    "                sections = page.split(\":\")[1]\n",
    "                sections = sections.split(\"-\")\n",
    "                if int(sections[0])<=int(line)<=int(sections[1]):\n",
    "                    return chapter[\"title\"],chapter['heTitle']\n",
    "    return ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_chapters(text_json, links):\n",
    "    refs = []\n",
    "    text_json[\"text_perakim\"] = []\n",
    "    text_json[\"chap_list\"] = []\n",
    "    daf_i = 1\n",
    "    j = 0\n",
    "    title = text_json[\"title\"]\n",
    "    current_perek = \"\"\n",
    "    for daf in text_json[\"text\"]:\n",
    "        if daf != []:\n",
    "            comment_i = 1\n",
    "            for comment in daf:\n",
    "                daf_num = math.floor(daf_i)\n",
    "                if daf_num == daf_i:\n",
    "                    amud = \"a\"\n",
    "                else:\n",
    "                    amud = \"b\"\n",
    "                daf_ref = str(daf_num)+amud\n",
    "                new_ref = title +\" \"+ daf_ref + \":\"+str(comment_i)\n",
    "                gemara_ref = \"\"\n",
    "                for link in links:\n",
    "                    if link[0] == new_ref:\n",
    "                        gemara_ref = link[1]\n",
    "                        break\n",
    "                if \"-\" in gemara_ref:\n",
    "                    gemara_ref = gemara_ref.split(\"-\")[0]\n",
    "                if gemara_ref != \"\":\n",
    "                    ref_perek = find_perek(gemara_ref)\n",
    "                    if ref_perek != current_perek:\n",
    "                        current_perek = ref_perek\n",
    "                        perek_info = {\"name_en\":ref_perek[0],\"name_he\":ref_perek[1]}\n",
    "                        text_json[\"text\"][j].insert(comment_i-1,perek_info)\n",
    "                comment_i += 1\n",
    "        daf_i += 0.5\n",
    "        j += 1\n",
    "    return text_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_body(hebrew_text, english_text, settings):\n",
    "    output = []\n",
    "    chap_num = 1\n",
    "    mishna_num = 1\n",
    "    title = hebrew_text[\"heTitle\"]\n",
    "    title_command = r\"\\newcommand{\\texttitle}{\"+title+\"}\"\n",
    "    divisions_en = hebrew_text[\"sectionNames\"]\n",
    "    divisions_he = []\n",
    "    with open('resources/section_names.csv') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            for division in divisions_en:\n",
    "                if row[0] == division:\n",
    "                    divisions_he.append(row[1])\n",
    "    if \"Daf\" in divisions_en:\n",
    "        hebrew_text = match_chapters(hebrew_text,link_list)       \n",
    "    for perek in hebrew_text[\"text\"]:\n",
    "        if any(perek):\n",
    "            if type(perek[0]) == dict and \"name_he\" in perek[0].keys():\n",
    "                output.append(r\"\\newchap{\"+parse_perek_title(perek[0])+\"}\")\n",
    "            if \"Daf\" in divisions_en:\n",
    "                daf = ((chap_num+1)/2)\n",
    "                if daf == round(daf):\n",
    "                    output.append(r\"\\addsec{דף \\hebrewnumeral{\"+str(round(daf))+\"}}\")              \n",
    "            else:\n",
    "                output.append(r\"\\addchap{\"+divisions_he[0]+r\" \\hebrewnumeral{\"+str(chap_num)+\"}}\")\n",
    "            for par in perek:\n",
    "                textblock = \"\"\n",
    "                if type(par) == dict and \"name_he\" in par.keys() and par[\"name_en\"] != \"Chapter 1\":\n",
    "                    if textblock != \"\":\n",
    "                        new_text = make_section(textblock,None, settings, chap_num, mishna_num)\n",
    "                        output.append(new_text)\n",
    "                    output.append(r\"\\addchap{\"+parse_perek_title(par)+\"}\")\n",
    "                else:\n",
    "                    while type(par)==list:\n",
    "                        new_par = \"\"\n",
    "                        for item in par:\n",
    "                            new_par += item\n",
    "                        par = new_par\n",
    "                    if type(par) != dict:\n",
    "                        textblock += par\n",
    "                mishna_num += 1\n",
    "            new_text = make_section(textblock,None, settings, chap_num, mishna_num)\n",
    "            if \"twocol\" in new_text and \"twocol\" in output[-1]:\n",
    "                new_text = new_text.replace(r\"\\twocol{\",\"\\par \")\n",
    "                output = output[0:-1]+[output[-1][0:-1]]+[new_text]\n",
    "            else:\n",
    "                output.append(new_text)\n",
    "        chap_num += 1\n",
    "        mishna_num = 1\n",
    "    return title_command, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_perek_title(perekDict):\n",
    "    chap_num = perekDict[\"name_en\"].replace(\"Chapter \",\"\")\n",
    "    title = r\"פרק \\hebrewnumeral{\"+chap_num+r\"}\\quad \"+perekDict[\"name_he\"]\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeformatting(text):\n",
    "    while \"<\" in text and \">\" in text:\n",
    "        loc1 = text.find(\"<\")\n",
    "        loc2 = text.find(\">\",loc1)+1\n",
    "        text = text.replace(text[loc1:loc2],\"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_section(hebrew_text, english, settings, chap_num, mishna_num):\n",
    "    if english != None:\n",
    "        english = english.replace(\"[\",\"{[\")\n",
    "        english = english.replace(\"]\",\"]}\")\n",
    "        output = r\"\\textblock{\"+hebrew_text+\"}{\"+english+\"}\"\n",
    "    elif settings[\"layout\"] == \"twocol\":\n",
    "        output= r\"\\twocol{\"+hebrew_text+\"}\"\n",
    "    else:\n",
    "        output= r\"\\textblock{\"+hebrew_text+\"}\"\n",
    "    with open('resources/html_tags_to_tex.csv') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            if row[0] in output:\n",
    "                output = output.replace(row[0],row[1])\n",
    "    output = removeformatting(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_format(template_lines,settings):\n",
    "    output = []\n",
    "    for line in template_lines:\n",
    "        if line[0:-1] in settings.keys():\n",
    "            setting_output = line[0:-1] + \"=\"+settings[line[0:-1]]+\",\\n\"\n",
    "            output.append(setting_output)\n",
    "        elif line[0:-1] == \"%setfontsize\":\n",
    "            fontsize = settings[\"fontsize\"]\n",
    "            skip = fontsize * settings[\"spacing\"]\n",
    "            fontsizestr = r\"\\fontsize{\"+str(fontsize)+r\"pt}{\"+str(round(skip,1))+r\"pt} \\selectfont\"\n",
    "            output.append(fontsizestr)\n",
    "        elif line[0:-1] == \"%sethebfont\":\n",
    "            if settings[\"hebboldfont\"] == None:\n",
    "                font = r\"\\setmainfont{\"+settings[\"hebfont\"]+r\"}\"\n",
    "            else:\n",
    "                font = r\"\\setmainfont[BoldFont = {\"+settings[\"hebboldfont\"]+r'}]{'+settings[\"hebfont\"]+r\"}\"\n",
    "            output.append(font)\n",
    "        elif line[0:-1] == \"%setengfont\" and settings[\"engfont\"] != None:\n",
    "            engfont = r'\\newfontfamily\\englishfont{'+settings[\"engfont\"]+r'}'\n",
    "            output.append(engfont)\n",
    "        elif line[0:-1] == \"%setparskip\" and settings[\"parskip\"] != None:\n",
    "            parskip = r'\\setlength{\\parskip}{'+settings[\"parskip\"]+'}'\n",
    "            output.append(parskip)\n",
    "        elif line[0:-1] == \"%pagenumber\":\n",
    "            if settings[\"pagenumloc\"] == \"topouter\":\n",
    "                pagenum = r\"\\fancyhead[LO,RE]{num}\"\n",
    "            elif settings[\"pagenumloc\"] == \"bottommiddle\":\n",
    "                pagenum = r\"\\fancyfoot[C]{num}\"\n",
    "            if settings[\"pagenumheb\"] == True:\n",
    "                pagenum = pagenum.replace(\"num\",r\"\\hebrewnumeral{\\thepage}\")\n",
    "            else:\n",
    "                pagenum = pagenum.replace(\"num\",r\"\\thepage\")\n",
    "            output.append(pagenum)\n",
    "        elif line[0:-1] == \"%header\":\n",
    "            if settings[\"headpos\"] == \"center\":\n",
    "                odd_header = r\"\\fancyhead[CO]{\"\n",
    "                even_header = r\"\\fancyhead[CE]{\"\n",
    "            elif settings[\"headpos\"] == \"inner\":\n",
    "                odd_header = r\"\\fancyhead[RO]{\"\n",
    "                even_header = r\"\\fancyhead[LE]{\"\n",
    "            if settings[\"evenhead\"] == \"title\":\n",
    "                even_header += r\"\\texttitle\"\n",
    "            elif settings[\"evenhead\"] == \"chapter\":\n",
    "                even_header += r\"\\chapname\"\n",
    "            elif settings[\"evenhead\"] == \"titlechapter\":\n",
    "                even_header += r\"\\texttitle \\space\\textendash\\space \\chapname\"\n",
    "            if settings[\"oddhead\"] == \"title\":\n",
    "                odd_header += r\"\\texttitle\"\n",
    "            elif settings[\"oddhead\"] == \"chapter\":\n",
    "                odd_header += r\"\\chapname\"\n",
    "            elif settings[\"oddhead\"] == \"titlechapter\":\n",
    "                odd_header += r\"\\texttitle \\space\\textendash\\space \\chapname\"\n",
    "            odd_header += \"}\"\n",
    "            even_header += \"}\"\n",
    "            output.append(odd_header)\n",
    "            output.append(even_header)\n",
    "        elif line[0:-1] == \"%chapfontsize\":\n",
    "            if \"chapfontsize\" in settings.keys():\n",
    "                headerfontcommand = r\"\\fontsize{\"+settings[\"chapfontsize\"]+\"}{\"+settings[\"chapfontsize\"]+r\"}\\selectfont\"\n",
    "            else:\n",
    "                headerfontcommand = r\"\\LARGE\"\n",
    "            output.append(headerfontcommand)\n",
    "        else:\n",
    "            output.append(line)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_settings = {\n",
    "    \"text\": \"Talmud/Bavli/Commentary/Ramban/Seder%20Tahorot/Chiddushei%20Ramban%20on%20Niddah/Hebrew/Chiddushei%20HaRamban%2C%20Jerusalem%201928-29\",\n",
    "    \"translation\":None,\n",
    "    \"paperheight\" : \"11in\",\n",
    "    \"paperwidth\" : \"8.5in\",\n",
    "    \"hebfont\":\"Frank Ruehl CLM\",\n",
    "    \"hebboldfont\":None,\n",
    "    \"engfont\":\"EB Garamond\",\n",
    "    \"top\" : \"0.5in\",\n",
    "    \"bottom\" :\"0.5in\",\n",
    "    \"inner\" : \"0.7in\",\n",
    "    \"outer\" : \"0.5in\",\n",
    "    \"fontsize\":10.5,\n",
    "    \"spacing\":2,\n",
    "    \"english\":False,\n",
    "    \"newpage\":False,\n",
    "    \"levels\":1,\n",
    "    \"layout\":\"twocol\",\n",
    "    \"parskip\":\"8pt\",\n",
    "    \"pagenumloc\":\"topouter\",\n",
    "    \"pagenumheb\":False,\n",
    "    \"headpos\":\"center\",\n",
    "    \"evenhead\":\"title\",\n",
    "    \"oddhead\":\"chapter\",\n",
    "    \"chapfontsize\":\"16pt\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bib_info(json):\n",
    "    source_data = {}\n",
    "    source_data[\"source\"] = json[\"versionSource\"]\n",
    "    source_data[\"license\"] = json[\"license\"]\n",
    "    source_data[\"version\"] = json[\"versionTitle\"]\n",
    "    return source_data\n",
    "\n",
    "def print_source_data(source_list):\n",
    "    output = []\n",
    "    output.append(r\"\\begin{itemize}\")\n",
    "    for source in source_list:\n",
    "        if \"NC\" in source[\"license\"] or \"Copyright\" in source[\"license\"]:\n",
    "            return [\"NC\",source[\"version\"]]\n",
    "        versiontitle = source[\"version\"].replace(\"-\",r\"\\textendash \")\n",
    "        output.append(r\"\\item \"+versiontitle)\n",
    "        if len(source_list) > 1:\n",
    "            output.append(r\"\\begin{itemize}\")\n",
    "        output.append(r\"\\item License: \"+source[\"license\"])\n",
    "        output.append(r\"\\item Source: \\url{\"+source[\"source\"]+\"}\")\n",
    "        if len(source_list) > 1:\n",
    "            output.append(r\"\\end{itemize}\")\n",
    "    output.append(r\"\\end{itemize}\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputpath = os.path.join(\"resources\",\"input.tex\")\n",
    "def pullinput(inputpath):\n",
    "    with open(inputpath, 'r', encoding='utf-8') as infile:\n",
    "        template_lines = list(infile.readlines())\n",
    "    return template_lines\n",
    "\n",
    "def writeoutput(outputpath, template, formatting):\n",
    "    sources = []\n",
    "    template_with_settings = set_format(template,formatting)\n",
    "    sefaria_json = pull_text(formatting[\"text\"])\n",
    "    sources.append(get_bib_info(sefaria_json))\n",
    "    if formatting[\"translation\"]!= None:\n",
    "        english_json = pull_text(formatting[\"translation\"])\n",
    "        sources.append(get_bib_info(english_json))\n",
    "        sefaria_result = make_body(sefaria_json,english_json,formatting)\n",
    "    else:\n",
    "        sefaria_result = make_body(sefaria_json, None, formatting)\n",
    "    body = sefaria_result[1]\n",
    "    title_command = sefaria_result[0]\n",
    "    source_listing = print_source_data(sources)\n",
    "    if source_listing[0] == \"NC\":\n",
    "        print(source_listing[1] + \" has a license which does not allow creation of this text.\")\n",
    "        return\n",
    "    with open(outputpath, 'w', encoding='utf-8') as outfile:\n",
    "        for line in template_with_settings:\n",
    "            if line == \"%title_here\\n\":\n",
    "                outfile.write(title_command)\n",
    "            elif line == \"%license info\\n\":\n",
    "                for item in source_listing:\n",
    "                    outfile.write(item)\n",
    "                    outfile.write(\"\\n\")\n",
    "            elif line == \"%body_here\\n\":\n",
    "                for newline in body:\n",
    "                    outfile.write(newline)\n",
    "                    outfile.write(\"\\n\")\n",
    "            else:\n",
    "                outfile.write(line)\n",
    "                if \"\\n\" not in line:\n",
    "                    outfile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://raw.githubusercontent.com/Sefaria/Sefaria-Export/master/json/Talmud/Bavli/Commentary/Ramban/Seder%20Tahorot/Chiddushei%20Ramban%20on%20Niddah/Hebrew/Chiddushei%20HaRamban%2C%20Jerusalem%201928-29.json\n"
     ]
    }
   ],
   "source": [
    "template_lines = pullinput(inputpath)\n",
    "outputname = \"output.tex\"\n",
    "writeoutput(outputname,template_lines,output_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['xelatex', '-interaction=nonstopmode', 'output.tex'], returncode=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(['xelatex', '-interaction=nonstopmode', outputname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
