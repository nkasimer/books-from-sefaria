{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-hebrew-numbers in c:\\users\\nathan\\anaconda3\\lib\\site-packages (0.2.3)\n",
      "Requirement already satisfied: PyYaml in c:\\users\\nathan\\anaconda3\\lib\\site-packages (from python-hebrew-numbers) (6.0)\n",
      "Collecting pdfrw\n",
      "  Downloading pdfrw-0.4-py2.py3-none-any.whl (69 kB)\n",
      "Installing collected packages: pdfrw\n",
      "Successfully installed pdfrw-0.4\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install python-hebrew-numbers\n",
    "!{sys.executable} -m pip install pdfrw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports various packages\n",
    "import json, urllib.request\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "import os, platform, subprocess, csv\n",
    "import math\n",
    "from hebrew_numbers import int_to_gematria\n",
    "import pdfrw\n",
    "from pdfrw import PdfReader, PdfWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function pulls a text from Sefaria's github repo, given a string with the name of the text in the repo's format\n",
    "#this will presumably be replaced with pulling a text from a downloaded copy of the sefaria repo\n",
    "def pull_text(string_for_link):\n",
    "    link = string_for_link.replace(\" \",\"%20\")\n",
    "    link = \"https://raw.githubusercontent.com/Sefaria/Sefaria-Export/master/json/\"+string_for_link+\".json\"\n",
    "    print(link)\n",
    "    with urllib.request.urlopen(link) as url:\n",
    "        text_json = json.loads(url.read().decode())\n",
    "    return text_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this generates a list of links between texts in sefaria\n",
    "#this is used to link comments in the gemara to gemara they're on\n",
    "def pull_links():\n",
    "    link_list = []#blank list to be filled in\n",
    "    for i in range(9):#this increments through all the github files that contain links\n",
    "        location = os.path.join(os.getcwd(),\"links\",\"links\"+str(i)+\".csv\")\n",
    "        with open(location, encoding=\"utf-8\") as csv_file:\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            next(csv_reader)#skips first row\n",
    "            for row in csv_reader:\n",
    "                if row[2] == \"commentary\":#only interested in commentaries\n",
    "                    link = []\n",
    "                    link.append(row[0])\n",
    "                    link.append(row[1])\n",
    "                    link_list.append(link)\n",
    "    return link_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_list = pull_links()#generates the list of comment links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_comment(comment_str, links):#matches a comment with the gemara it's on\n",
    "    for link in links:#for every link in the list\n",
    "        #if the text is in the list, return the text it's linked to\n",
    "        if comment_str in link[0]:\n",
    "            return link[1]\n",
    "        elif comment_str in link[1]:\n",
    "            return link[0]\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_json(masekhet):\n",
    "    #this gets the index json for a particular masekhet, which includes info about perakim.\n",
    "    masekhet = masekhet.replace(\" \",\"_\")\n",
    "    link = \"https://raw.githubusercontent.com/Sefaria/Sefaria-Export/master/schemas/\"+masekhet+\".json\"\n",
    "    with urllib.request.urlopen(link) as url:\n",
    "        index_json = json.loads(url.read().decode())\n",
    "    chaps = index_json[\"alts\"][\"Chapters\"][\"nodes\"]\n",
    "    return chaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_perek(name):\n",
    "    if \" on \" in name:\n",
    "        masekhet_start = name.find(\" on \")+len(\" on \")\n",
    "        name = name[masekhet_start:]\n",
    "    name = name.split(' ')\n",
    "    if len(name)==2:\n",
    "        masekhet = name[0]\n",
    "    else:\n",
    "        masekhet = name[0]+\" \"+name[1]\n",
    "    daf,line = name[-1].split(\":\")\n",
    "    chapters = get_index_json(masekhet)\n",
    "    ref = masekhet+\" \"+daf\n",
    "    for chapter in chapters:\n",
    "        for page in chapter[\"refs\"]:\n",
    "            if \":\" not in page and page==ref:\n",
    "                return chapter[\"title\"],chapter['heTitle']\n",
    "            elif \":\" in page and ref in page:\n",
    "                sections = page.split(\":\")[1]\n",
    "                sections = sections.split(\"-\")\n",
    "                if len(sections)>1:\n",
    "                    if int(sections[0])<=int(line)<=int(sections[1]):\n",
    "                        return chapter[\"title\"],chapter['heTitle']\n",
    "                elif len(sections) == 1:\n",
    "                    if int(sections[0])==int(line):\n",
    "                        return chapter[\"title\"],chapter['heTitle']\n",
    "    return ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_chapters(text_json, links):\n",
    "    #adds perek breaks to text json\n",
    "    refs = []\n",
    "    text_json[\"text_perakim\"] = []#original text, but with perakim breaks noted\n",
    "    text_json[\"chap_list\"] = []#list of chapter titles\n",
    "    daf_i = 1#initializing counters.\n",
    "    #Sefaria puts a blank spot for daf 1, so it starts with 1 not 2.\n",
    "    title = text_json[\"title\"]\n",
    "    current_perek = \"\"\n",
    "    j=0\n",
    "    for daf in text_json[\"text\"]:\n",
    "        if daf != []:#if daf isn't empty\n",
    "            comment_i = 1#comment counter\n",
    "            for comment in daf:\n",
    "                daf_num = math.floor(daf_i)#rounds daf down from 0.5 to get real number\n",
    "                if daf_num == daf_i:\n",
    "                    amud = \"a\"\n",
    "                else:\n",
    "                    amud = \"b\"#for daf with 0.5, it's daf X amud b\n",
    "                daf_ref = str(daf_num)+amud #makes davening number, like 4b\n",
    "                new_ref = title +\" \"+ daf_ref + \":\"+str(comment_i)\n",
    "                #adds masekhet name to daf reference\n",
    "                if \"commentary\" in text_json[\"categories\"]:\n",
    "                    gemara_ref = \"\"\n",
    "                    for link in links:#for every link in link list\n",
    "                        if link[0] == new_ref:#if the link is do the relevant daf\n",
    "                            gemara_ref = link[1]\n",
    "                            break\n",
    "                    if \"-\" in gemara_ref:#if a reference spans a daf\n",
    "                        gemara_ref = gemara_ref.split(\"-\")[0]#returns the first part\n",
    "                    if gemara_ref != \"\":\n",
    "                        ref_perek = find_perek(gemara_ref)#looks up the perek of the daf of gemara\n",
    "                        if ref_perek != current_perek:#if the reference is a new perek\n",
    "                            current_perek = ref_perek#set current perek\n",
    "                            perek_info = {\"name_en\":ref_perek[0],\"name_he\":ref_perek[1]}\n",
    "                            text_json[\"text\"][j].insert(comment_i-1,perek_info)\n",
    "                            #the above adds a dict with info on the perek into the text json\n",
    "                else:\n",
    "                    ref_perek = find_perek(new_ref)\n",
    "                    if ref_perek != current_perek:#if the reference is a new perek\n",
    "                        current_perek = ref_perek#set current perek\n",
    "                        perek_info = {\"name_en\":ref_perek[0],\"name_he\":ref_perek[1]}\n",
    "                        if perek_info not in text_json[\"text\"] and perek_info != {'name_en': 'N', 'name_he': 'i'}:\n",
    "                            text_json[\"text\"][j].insert(comment_i-1,perek_info)\n",
    "                        #the above adds a dict with info on the perek into the text json\n",
    "                comment_i += 1\n",
    "        daf_i += 0.5\n",
    "        j += 1\n",
    "    return text_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_body(hebrew_text, english_text, settings, commentaries):\n",
    "    output = []\n",
    "    chap_num = 1\n",
    "    mishna_num = 1# lav davka mishna, just the smaller divisions of the text\n",
    "    title = hebrew_text[\"heTitle\"]\n",
    "    title_command = r\"\\newcommand{\\texttitle}{\"+title+\"}\"#sets title\n",
    "    divisions_en = hebrew_text[\"sectionNames\"] #gets names of the sections for the specific text\n",
    "    divisions_he = []\n",
    "    #the following uses the CSV of section names to get the Hebrew sections names\n",
    "    with open('resources/section_names.csv', encoding='utf-8') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            for division in divisions_en:\n",
    "                if row[0] == division:\n",
    "                    divisions_he.append(row[1])\n",
    "    if \"Daf\" in divisions_en:\n",
    "        #if the text is based on dappim, run the script to add perakim notations\n",
    "        hebrew_text = match_chapters(hebrew_text,link_list)       \n",
    "    for perek in hebrew_text[\"text\"]:\n",
    "        if any(perek):\n",
    "            if type(perek[0]) == dict and \"name_he\" in perek[0].keys():\n",
    "                #if there's a new perek dict note, add the LaTeX code for the new perek\n",
    "                new_chap_text = r\"\\newchap{\"+parse_perek_title(perek[0])+\"}\"\n",
    "                if new_chap_text not in output:\n",
    "                    output.append(new_chap_text)\n",
    "            if \"Daf\" in divisions_en:\n",
    "                #this adds daf numbers for each new daf, ignoring the amud break\n",
    "                daf = ((chap_num+1)/2)\n",
    "                if daf == round(daf):\n",
    "                    daftitle = int_to_gematria(round(daf), gershayim=False)\n",
    "                    if settings[\"newpage\"] == 1:\n",
    "                        output.append(r\"\\clearpage\")\n",
    "                    output.append(r\"\\newsection{דף \"+daftitle+\"}\")              \n",
    "            else:\n",
    "                if settings[\"newpage\"] == 1:\n",
    "                    output.append(r\"\\clearpage\")\n",
    "                output.append(r\"\\newsection{\"+divisions_he[0]+\" \"+int_to_gematria(chap_num, gershayim=False)+\"}\")\n",
    "            for par in perek:\n",
    "                #prints next block of text\n",
    "                textblock = \"\"\n",
    "                comments = []\n",
    "                if type(par) == dict and \"name_he\" in par.keys() and par[\"name_en\"] != \"Chapter 1\":\n",
    "                    if textblock != \"\":\n",
    "                        new_text = make_section(textblock,None, settings, chap_num, mishna_num, commentaries)\n",
    "                        output.append(new_text)\n",
    "                else:\n",
    "                    while type(par)==list:\n",
    "                        new_par = \"\"\n",
    "                        for item in par:\n",
    "                            new_par += item\n",
    "                        par = new_par\n",
    "                    if type(par) != dict:\n",
    "                        textblock += par\n",
    "                mishna_num += 1\n",
    "                new_text = make_section(textblock,None, settings, chap_num, mishna_num, commentaries)\n",
    "                if new_text != \"\":\n",
    "                    output.append(new_text)\n",
    "        chap_num += 1\n",
    "        mishna_num = 1\n",
    "    if settings[\"layout\"] == \"twocol\":\n",
    "        line_i = 0\n",
    "        newsection_bool = True\n",
    "        in_cols = False\n",
    "        lastline = \"\"\n",
    "        for line in output:\n",
    "            if \"newsection\" in line or \"newchap\" in line:\n",
    "                newsection_bool = True\n",
    "                if in_cols == True:\n",
    "                    #print(\"END TWOCOLS\")\n",
    "                    output[line_i-1] = output[line_i-1]+\"}\\n\"\n",
    "            elif \"newsection\" not in line and \"newchap\" not in line:\n",
    "                if newsection_bool == True:\n",
    "                    newsection_bool = False\n",
    "                    output[line_i] = r\"\\twocol{\"+line\n",
    "                    in_cols = True\n",
    "                    #print(\"BEGIN TWOCOLS\")\n",
    "\n",
    "            lastline = line\n",
    "            line_i += 1\n",
    "        output.append(r\"}\")\n",
    "    return title_command, output, title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twocol_combine(output):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_perek_title(perekDict):\n",
    "    chap_num = perekDict[\"name_en\"].replace(\"Chapter \",\"\")\n",
    "    title = r\"פרק \\hebrewnumeral{\"+chap_num+r\"} \"+perekDict[\"name_he\"]\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeformatting(text):\n",
    "    while \"<\" in text and \">\" in text:\n",
    "        loc1 = text.find(\"<\")\n",
    "        loc2 = text.find(\">\",loc1)+1\n",
    "        text = text.replace(text[loc1:loc2],\"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_section(hebrew_text, english, settings, chap_num, mishna_num, commentaries):\n",
    "    #turns a block of text into a latex section using the \\textblock or \\twocol command\n",
    "    if english != \"\" and english != None:\n",
    "        english = english.replace(\"[\",\"{[\")\n",
    "        english = english.replace(\"]\",\"]}\")\n",
    "        output = r\"\\textblock{\"+hebrew_text+\"}{\"+english+\"}\"\n",
    "    elif settings[\"layout\"] == \"twocol\":\n",
    "        #output= r\"\\twocol{\"+hebrew_text+\"}\"\n",
    "        output = hebrew_text\n",
    "    else:\n",
    "        output= r\"\\textblock{\"+hebrew_text+\"}\"\n",
    "    comment_i = 1\n",
    "    for commentary in commentaries:\n",
    "        #output+=\"\\n\"\n",
    "        output+=get_comments(chap_num,mishna_num,commentary,comment_i)\n",
    "        comment_i += 1\n",
    "    with open('resources/text_replacements.csv',encoding='utf=8') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            if row[0] in output:\n",
    "                output = output.replace(row[0],row[1])\n",
    "    output = removeformatting(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments(i,j,commentary,comment_i):\n",
    "    try:\n",
    "        chap = commentary[\"text\"][i-1]\n",
    "    except IndexError:\n",
    "        return \"\"\n",
    "    if len(chap)<j:\n",
    "        return \"\"\n",
    "    #command_name = r\"\\comment_\"+str(comment_i)\n",
    "    comment_text = \"\\n\"+r\"\\comment\"+chr(comment_i+96)+\"{\"\n",
    "#     for comment in chap[j-1]:\n",
    "#         if comment == \"\":\n",
    "#             continue\n",
    "#         if comment[-1] == \" \":\n",
    "#             comment = comment[:-1]\n",
    "#         comment_text += comment\n",
    "    content = chap[j-1]\n",
    "    if type(content) == list:\n",
    "        if content == []:\n",
    "            return \"\"\n",
    "        else:\n",
    "            content = content[0]\n",
    "    content = content.replace(r\"\\par\",\"\")\n",
    "    comment_text += content\n",
    "    comment_text += \"}\"\n",
    "    #comment_text = comment_text.replace(r\"\\quad }\",\"}\")\n",
    "    if \"{}\" in comment_text:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return comment_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_format(template_lines,settings):\n",
    "    output = []\n",
    "    #this sets the format for the text in the LaTeX preamble.\n",
    "    #ths line[0:-1] is the text of the line in LaTeX being converted by the script.\n",
    "    #the -1 is needed to exclude the \\n for line break at the end of each line.\n",
    "    #these work by converting a LaTeX comment for a specific formatting piece to a command, based on what's in the settings json.\n",
    "    for line in template_lines:\n",
    "        if line[0:-1] in settings.keys():\n",
    "            setting_output = line[0:-1] + \"=\"+settings[line[0:-1]]+\",\\n\"\n",
    "            output.append(setting_output)\n",
    "        elif line[0:-1] == \"%setfontsize\":\n",
    "            fontsize = settings[\"fontsize\"]\n",
    "            skip = fontsize * settings[\"spacing\"]\n",
    "            fontsizestr = r\"\\fontsize{\"+str(fontsize)+r\"pt}{\"+str(round(skip,1))+r\"pt} \\selectfont\"\n",
    "            output.append(fontsizestr)\n",
    "        elif line[0:-1] == \"%sethebfont\":\n",
    "            if settings[\"hebboldfont\"] == \"\":\n",
    "                font = r\"\\setmainfont{\"+settings[\"hebfont\"]+r\"}\"\n",
    "            else:\n",
    "                font = r\"\\setmainfont[BoldFont = {\"+settings[\"hebboldfont\"]+r'}]{'+settings[\"hebfont\"]+r\"}\"\n",
    "            output.append(font)\n",
    "        elif line[0:-1] == \"%setengfont\" and settings[\"engfont\"] != 0:\n",
    "            engfont = r'\\newfontfamily\\englishfont{'+settings[\"engfont\"]+r'}'\n",
    "            output.append(engfont)\n",
    "        elif line[0:-1] == \"%setparskip\" and settings[\"parskip\"] != 0:\n",
    "            parskip = r'\\setlength{\\parskip}{'+settings[\"parskip\"]+'}'\n",
    "            output.append(parskip)\n",
    "        elif line[0:-1] == \"%pagenumber\":\n",
    "            if settings[\"pagenumloc\"] == \"topouter\":\n",
    "                pagenum = r\"\\fancyhead[LO,RE]{num}\"\n",
    "            elif settings[\"pagenumloc\"] == \"bottommiddle\":\n",
    "                pagenum = r\"\\fancyfoot[C]{num}\"\n",
    "            if settings[\"pagenumheb\"] == True:\n",
    "                pagenum = pagenum.replace(\"num\",r\"\\hebrewnumeral{\\thepage}\")\n",
    "            else:\n",
    "                pagenum = pagenum.replace(\"num\",r\"\\thepage\")\n",
    "            output.append(pagenum)\n",
    "        elif line[0:-1] == \"%header\":\n",
    "            if settings[\"headpos\"] == \"center\":\n",
    "                odd_header = r\"\\fancyhead[CO]{\"\n",
    "                even_header = r\"\\fancyhead[CE]{\"\n",
    "            elif settings[\"headpos\"] == \"inner\":\n",
    "                odd_header = r\"\\fancyhead[RO]{\"\n",
    "                even_header = r\"\\fancyhead[LE]{\"\n",
    "            if settings[\"evenhead\"] == \"title\":\n",
    "                even_header += r\"\\texttitle\"\n",
    "            elif settings[\"evenhead\"] == \"chapter\":\n",
    "                even_header += r\"\\chapname\"\n",
    "            elif settings[\"evenhead\"] == \"titlechapter\":\n",
    "                even_header += r\"\\texttitle \\space\\textendash\\space \\chapname\"\n",
    "            if settings[\"oddhead\"] == \"title\":\n",
    "                odd_header += r\"\\texttitle\"\n",
    "            elif settings[\"oddhead\"] == \"chapter\":\n",
    "                odd_header += r\"\\chapname\"\n",
    "            elif settings[\"oddhead\"] == \"titlechapter\":\n",
    "                odd_header += r\"\\texttitle \\space\\textendash\\space \\chapname\"\n",
    "            odd_header += \"}\"\n",
    "            even_header += \"}\"\n",
    "            output.append(odd_header)\n",
    "            output.append(even_header)\n",
    "        elif line[0:-1] == \"%chapfontsize\":\n",
    "            if \"chapfontsize\" in settings.keys():\n",
    "                headerfontcommand = r\"\\fontsize{\"+settings[\"chapfontsize\"]+\"}{\"+settings[\"chapfontsize\"]+r\"}\\selectfont\"\n",
    "            else:\n",
    "                headerfontcommand = r\"\\LARGE\"\n",
    "            output.append(headerfontcommand)\n",
    "        elif line[0:-1] == \"%setcolumnsep\":\n",
    "            output.append(r\"\\setlength{\\columnsep}{\"+settings[\"colsep\"]+\"}\")\n",
    "        else:\n",
    "            output.append(line)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bib_info(json):\n",
    "    #puts bibliographic info in a dict\n",
    "    source_data = {}\n",
    "    source_data[\"source\"] = json[\"versionSource\"]\n",
    "    if \"license\" in json.keys():\n",
    "        source_data[\"license\"] = json[\"license\"]\n",
    "    else:\n",
    "        source_data[\"license\"] = \"CC-BY\"\n",
    "    source_data[\"version\"] = json[\"versionTitle\"]\n",
    "    return source_data\n",
    "\n",
    "def print_source_data(source_list):\n",
    "    output = []\n",
    "    output.append(r\"\\begin{itemize}\")\n",
    "    #puts every piece of bibliographic info into a copyright notice\n",
    "    for source in source_list:\n",
    "        if \"NC\" in source[\"license\"] or \"Copyright\" in source[\"license\"]:\n",
    "            return [\"NC\",source[\"version\"]]\n",
    "        versiontitle = source[\"version\"].replace(\"-\",r\"\\textendash \")\n",
    "        output.append(r\"\\item[$\\bullet$] \"+versiontitle)\n",
    "        if len(source_list) > 1:\n",
    "            output.append(r\"\\begin{itemize}\")\n",
    "        output.append(r\"\\item[$\\bullet$] License: \"+source[\"license\"])\n",
    "        output.append(r\"\\item[$\\bullet$] Source: \\url{\"+source[\"source\"]+\"}\")\n",
    "        if len(source_list) > 1:\n",
    "            output.append(r\"\\end{itemize}\")\n",
    "    output.append(r\"\\end{itemize}\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reads template file\n",
    "inputpath = os.path.join(\"resources\",\"input.tex\")\n",
    "coverinpath = os.path.join(\"resources\",\"input_cover.tex\")\n",
    "def pullinput(inputpath):\n",
    "    with open(inputpath, 'r', encoding='utf-8') as infile:\n",
    "        template_lines = list(infile.readlines())\n",
    "    return template_lines\n",
    "\n",
    "#converts input into output\n",
    "# def writeoutputOld(outputpath, template, formatting):\n",
    "#     sources = []\n",
    "#     template_with_settings = set_format(template,formatting)#reads settings\n",
    "#     sefaria_json = pull_text(formatting[\"text\"])#pulls json from Sefaria\n",
    "#     sources.append(get_bib_info(sefaria_json))#puts bibliographic info in sources list\n",
    "#     commentaries = []\n",
    "#     for commentary in formatting[\"commentary\"]:\n",
    "#         comments_json = pull_text(commentary)\n",
    "#         commentaries.append(comments_json)\n",
    "#     if formatting[\"translation\"]!= \"\":\n",
    "#         #pulls translation, if any, and adds to bibliographic list\n",
    "#         english_json = pull_text(formatting[\"translation\"])\n",
    "#         sources.append(get_bib_info(english_json))\n",
    "#         sefaria_result = make_body(sefaria_json,english_json,formatting,commentaries)\n",
    "#     else:\n",
    "#         sefaria_result = make_body(sefaria_json, None, formatting,commentaries)\n",
    "#     body = sefaria_result[1]\n",
    "#     title_command = sefaria_result[0]\n",
    "#     source_listing = print_source_data(sources)\n",
    "#     if source_listing[0] == \"NC\":#stops the script if the license doesn't allow the text to run\n",
    "#         print(source_listing[1] + \" has a license which does not allow creation of this text.\")\n",
    "#         return\n",
    "#     with open(outputpath, 'w', encoding='utf-8') as outfile:\n",
    "#         for line in template_with_settings:\n",
    "#             if line == \"%title_here\\n\":\n",
    "#                 outfile.write(title_command)\n",
    "#             elif line == \"%license info\\n\":\n",
    "#                 for item in source_listing:\n",
    "#                     outfile.write(item)\n",
    "#                     outfile.write(\"\\n\")\n",
    "#             elif line == \"%body_here\\n\":\n",
    "#                 for newline in body:\n",
    "#                     outfile.write(newline)\n",
    "#                     outfile.write(\"\\n\")\n",
    "#             else:\n",
    "#                 outfile.write(line)\n",
    "#                 if \"\\n\" not in line:\n",
    "#                     outfile.write(\"\\n\")\n",
    "#     cover_title_heb = title_to_cover(title_command)\n",
    "#     #eng_title_cover = \n",
    "#     if \"title\" in formatting.keys():\n",
    "#          return formatting[\"title\"]\n",
    "#     else:\n",
    "#         return cover_title_heb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_output(lines,textsettings):\n",
    "    if textsettings[\"range\"] == \"all\":\n",
    "        return lines\n",
    "    else:\n",
    "        array = range_str(textsettings[\"range\"])\n",
    "        sorted_lines = []\n",
    "        limited_lines = []\n",
    "        onechap = []\n",
    "        for line in lines:\n",
    "            if \"newchap\" not in line:\n",
    "                onechap.append(line)\n",
    "            else:\n",
    "                sorted_lines.append(onechap)\n",
    "                onechap = [line]\n",
    "        for chap in array:\n",
    "            print(chap)\n",
    "            for line in sorted_lines[chap]:\n",
    "                limited_lines.append(line)\n",
    "        return limited_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def range_str(string):\n",
    "    rng_array = []\n",
    "    ranges = string.split(\",\")\n",
    "    for numbers in ranges:\n",
    "        if \"-\" not in numbers:\n",
    "            rng_array.append(int(numbers))\n",
    "        else:\n",
    "            start_end = numbers.split(\"-\")\n",
    "            start = int(start_end[0])\n",
    "            end = int(start_end[1])\n",
    "            for number in range(start,end+1):\n",
    "                rng_array.append(number)\n",
    "    return rng_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converts input into output\n",
    "def writeoutput(outputpath, template, formatting):\n",
    "    sources = []\n",
    "    parts = []\n",
    "    template_with_settings = set_format(template,formatting)#reads settings\n",
    "    for text in formatting[\"texts\"]:\n",
    "        \n",
    "        sefaria_json = pull_text(text[\"text\"])#pulls json from Sefaria\n",
    "        bib_data = get_bib_info(sefaria_json)\n",
    "        sources.append(bib_data)#puts bibliographic info in sources list\n",
    "        commentaries = []\n",
    "        for commentary in text[\"commentary\"]:\n",
    "            comments_json = pull_text(commentary)\n",
    "            bib_data = get_bib_info(comments_json)\n",
    "            sources.append(bib_data)\n",
    "            commentaries.append(comments_json)\n",
    "        if text[\"translation\"]!= \"\":\n",
    "            #pulls translation, if any, and adds to bibliographic list\n",
    "            english_json = pull_text(formatting[\"translation\"])\n",
    "            sources.append(get_bib_info(english_json))\n",
    "            sefaria_result = make_body(sefaria_json,english_json,formatting,commentaries)\n",
    "        else:\n",
    "            sefaria_result = make_body(sefaria_json, None, formatting,commentaries)\n",
    "        content_limited = limit_output(sefaria_result[1],text)\n",
    "        part = {\"title\":sefaria_result[2],\"content\":content_limited}\n",
    "        parts.append(part)\n",
    "#         parts.append(sefaria_result[1])\n",
    "#         titles.append(sefaria_result[2])\n",
    "#         title_command = sefaria_result[0]\n",
    "        source_listing = print_source_data(sources)\n",
    "        if source_listing[0] == \"NC\":#stops the script if the license doesn't allow the text to run\n",
    "            print(source_listing[1] + \" has a license which does not allow creation of this text.\")\n",
    "            return\n",
    "    title_command = r\"\\newcommand{\\texttitle}{\"+formatting[\"titleheb\"]+\"}\"\n",
    "    with open(outputpath, 'w', encoding='utf-8') as outfile:#, open(\"test.txt\",'w',encoding='utf-8') as testfile:\n",
    "        for line in template_with_settings:\n",
    "            if line == \"%title_here\\n\":\n",
    "                outfile.write(title_command)\n",
    "            elif line == \"%license info\\n\":\n",
    "                for item in source_listing:\n",
    "                    outfile.write(item)\n",
    "                    outfile.write(\"\\n\")\n",
    "            elif line == \"%body_here\\n\":\n",
    "                if len(parts) == 1:\n",
    "                    for newline in parts[0][\"content\"]:\n",
    "                        outfile.write(newline+\"\\n\")\n",
    "                        #testfile.write(newline+\"\\n\")\n",
    "                elif len(parts)>1:\n",
    "                    for part in parts:\n",
    "                        outfile.write(r\"\\addpart{\"+part[\"title\"]+\"}\")\n",
    "                        for newline in part[\"content\"]:\n",
    "                            outfile.write(newline+\"\\n\")\n",
    "                            #testfile.write(newline+\"\\n\")\n",
    "            else:\n",
    "                outfile.write(line)\n",
    "                if \"\\n\" not in line:\n",
    "                    outfile.write(\"\\n\")\n",
    "    cover_title_heb = title_to_cover(title_command)\n",
    "    #eng_title_cover = \n",
    "    if \"title\" in formatting.keys():\n",
    "         return formatting[\"title\"]\n",
    "    else:\n",
    "        return cover_title_heb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cover(outputpath,cover_template,title,settings,pages):\n",
    "    coverOutPath = outputpath.replace(\".tex\",\"_cover.tex\")\n",
    "    inches = calc_spine_width(pages,settings)\n",
    "    with open(coverOutPath,'w',encoding='utf-8') as outfile:\n",
    "        for line in cover_template:\n",
    "            if line == \"%hebtitle\\n\":\n",
    "                outfile.write(title)\n",
    "            elif line == \"%backgroundcolor\\n\":\n",
    "                background_command = r\"\\definecolor{background}{HTML}{\"+settings[\"covercolor\"]+\"}\"\n",
    "                outfile.write(background_command+\"\\n\")\n",
    "            elif line == \"%textcolor\\n\":\n",
    "                text_command = r\"\\definecolor{text}{HTML}{\"+settings[\"covertextcolor\"]+\"}\"\n",
    "                outfile.write(text_command+\"\\n\")\n",
    "            elif line == \"%height\\n\":\n",
    "                if settings[\"covertype\"] == \"hardcover\":\n",
    "                    pageheight = float(settings[\"paperheight\"].replace(\"in\",\"\"))+1.5\n",
    "                elif settings[\"covertype\"] == \"softcover\":\n",
    "                    pageheight = float(settings[\"paperheight\"].replace(\"in\",\"\"))\n",
    "                coverheight = \"coverheight=\"+str(pageheight)+\"in,\\n\"\n",
    "                outfile.write(coverheight)\n",
    "            elif line == \"%width\\n\":\n",
    "                if settings[\"covertype\"] == \"hardcover\":\n",
    "                    pagewidth = float(settings[\"paperwidth\"].replace(\"in\",\"\"))+.75\n",
    "                elif settings[\"covertype\"] == \"softcover\":\n",
    "                    pagewidth = float(settings[\"paperwidth\"].replace(\"in\",\"\"))\n",
    "                coverwidth = \"coverwidth=\"+str(pagewidth)+\"in,\\n\"\n",
    "                outfile.write(coverwidth)\n",
    "            elif line == \"%spinewidth\\n\":\n",
    "                outfile.write(\"spinewidth=\"+str(inches)+\"in,\\n\")\n",
    "            elif line == \"%bleedwidth\\n\":\n",
    "#                 if settings[\"covertype\"] == \"hardcover\":\n",
    "                outfile.write(\"bleedwidth=.125in,\\n\")\n",
    "#                 elif settings[\"covertype\"] == \"softcover\":\n",
    "#                     outfile.write(\"bleedwidth=0in,\\n\")\n",
    "            elif \"%spinetextheight\" in line:\n",
    "                spine_txt_ht = min(float(inches),0.375)\n",
    "                inches_spine_text = str(0.85 * spine_txt_ht)\n",
    "                spine_ht_command = r\"\\fontsize{\"+inches_spine_text+\"in}{\"+inches_spine_text+\"in}\\selectfont\"\n",
    "                outfile.write(spine_ht_command)\n",
    "            elif \"%backtext\" in line:\n",
    "                if \"backtext\" in settings.keys():\n",
    "                    outfile.write(settings[\"backtext\"])\n",
    "            else:\n",
    "                outfile.write(line)\n",
    "                if \"\\n\" not in line:\n",
    "                    outfile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_spine_width(pages,settings):\n",
    "    if settings[\"covertype\"]==\"softcover\":\n",
    "        return (pages / 444) + 0.06\n",
    "    elif settings[\"covertype\"]==\"hardcover\":\n",
    "        with open('resources/spine_width.csv', encoding='utf-8') as csv_file:\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            spine_width = 0\n",
    "            for row in csv_reader:\n",
    "                if int(row[0])<=pages<=int(row[1]):\n",
    "                    return row[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_to_cover(heb_title):\n",
    "    heb_title = heb_title[24:-1]\n",
    "    heb_title_cover_list = heb_title.split()[::-1]\n",
    "    title_for_cover_heb = \"\"\n",
    "    for word in heb_title_cover_list:\n",
    "        title_for_cover_heb += word + ' '\n",
    "    title_for_cover_heb = title_for_cover_heb[0:-1]\n",
    "    return title_for_cover_heb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flips PDF for print on demand\n",
    "def flip_PDF(inpfn):\n",
    "    rotate = 180\n",
    "    #ranges = [[int(y) for y in x.split('-')] for x in ranges]\n",
    "    outname = inpfn.split(\".pdf\")\n",
    "    outfn = outname[0]+\".rotated.\"+outname[1]+\"pdf\"\n",
    "    print(outfn)\n",
    "    #outfn = 'rotate.%s' % os.path.basename(inpfn)\n",
    "    trailer = PdfReader(inpfn)\n",
    "    pages = trailer.pages\n",
    "\n",
    "    ranges = [[1, len(pages)]]\n",
    "\n",
    "    for onerange in ranges:\n",
    "        onerange = (onerange + onerange[-1:])[:2]\n",
    "        for pagenum in range(onerange[0]-1, onerange[1]):\n",
    "            pages[pagenum].Rotate = (int(pages[pagenum].inheritable.Rotate or\n",
    "                                         0) + rotate) % 360\n",
    "\n",
    "    outdata = PdfWriter(outfn)\n",
    "    outdata.trailer = trailer\n",
    "    outdata.write()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://raw.githubusercontent.com/Sefaria/Sefaria-Export/master/json/Talmud/Bavli/Seder%20Tahorot/Niddah/Hebrew/Wikisource%20Talmud%20Bavli.json\n",
      "https://raw.githubusercontent.com/Sefaria/Sefaria-Export/master/json/Talmud/Bavli/Commentary/Rashi/Seder%20Tahorot/Rashi%20on%20Niddah/Hebrew/Vilna%20Edition.json\n",
      "2\n",
      "3\n",
      "4\n",
      "https://raw.githubusercontent.com/Sefaria/Sefaria-Export/master/json/Talmud/Bavli/Commentary/Ramban/Seder%20Tahorot/Chiddushei%20Ramban%20on%20Niddah/Hebrew/Chiddushei%20HaRamban%2C%20Jerusalem%201928-29.json\n"
     ]
    }
   ],
   "source": [
    "template_lines = pullinput(inputpath)\n",
    "# for line in template_lines:\n",
    "#     print(line)\n",
    "outputname = \"output.tex\"\n",
    "with open('book_settings.json',encoding='utf=8') as json_file:\n",
    "    book_settings = json.load(json_file)\n",
    "title_heb = writeoutput(outputname,template_lines,book_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output.rotated.pdf\n"
     ]
    }
   ],
   "source": [
    "subprocess.run(['xelatex', '-interaction=nonstopmode', outputname])\n",
    "subprocess.run(['xelatex', '-interaction=nonstopmode', outputname])\n",
    "flip_PDF(outputname.replace(\".tex\",\".pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = len(PdfReader(outputname.replace(\".tex\",\".pdf\")).pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covertemplate = pullinput(coverinpath)\n",
    "make_cover(outputname,covertemplate,title_heb,book_settings,pages)\n",
    "coveroutputname = outputname.replace(\".tex\",\"_cover.tex\")\n",
    "subprocess.run(['xelatex', '-interaction=nonstopmode', coveroutputname])\n",
    "flip_PDF(coveroutputname.replace(\".tex\",\".pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
